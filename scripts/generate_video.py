#!/usr/bin/env python3
from dotenv import load_dotenv
load_dotenv()

import os
import json
import gspread
import requests
import tempfile
from datetime import datetime
from google.oauth2.service_account import Credentials
from google.oauth2.credentials import Credentials as OAuthCredentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload

SCOPES = [
    'https://www.googleapis.com/auth/spreadsheets',
    'https://www.googleapis.com/auth/youtube.upload'
]
SPREADSHEET_ID = '15_ixYlyRp9sOlS0tdklhz6wQmwRxWlOL9cPndFWwOFo'

# YouTube OAuth tokens (from GitHub Secrets)
YOUTUBE_TOKENS = {
    1: 'TOKEN_1',  # Channel 1-9
    2: 'TOKEN_2',  # Channel 10-18
    3: 'TOKEN_3',  # Channel 19-27
}

# Cache for channel info from spreadsheet
_channel_info_cache = None

def get_channel_info_from_sheet(sh):
    """Read channel information from '27„ÉÅ„É£„É≥„Éç„É´‰∏ÄË¶ß' sheet."""
    global _channel_info_cache

    if _channel_info_cache is not None:
        return _channel_info_cache

    try:
        ws = sh.worksheet('27„ÉÅ„É£„É≥„Éç„É´‰∏ÄË¶ß')
        all_data = ws.get_all_values()

        channel_info = {}
        for row in all_data[1:]:  # Skip header
            if len(row) >= 3:
                try:
                    token_num = int(row[0])
                    email = row[1]
                    channel_name = row[2]
                    channel_info[token_num] = {
                        'email': email,
                        'name': channel_name if channel_name != 'ÔºàÊú™Ë®≠ÂÆöÔºâ' else None
                    }
                except (ValueError, IndexError):
                    continue

        _channel_info_cache = channel_info
        return channel_info
    except Exception as e:
        print(f"  ‚ö†Ô∏è „ÉÅ„É£„É≥„Éç„É´ÊÉÖÂ†±Ë™≠„ÅøËæº„Åø„Ç®„É©„Éº: {e}")
        return {}

def get_channel_name(sh, channel_id):
    """Get channel name for the given channel ID."""
    channel_info = get_channel_info_from_sheet(sh)

    # Get channel number from environment or use channel_id
    channel_number = int(os.environ.get('CHANNEL_NUMBER', channel_id))

    info = channel_info.get(channel_number, {})
    return info.get('name')

# Fallback channel names (used when spreadsheet doesn't have the info)
CHANNELS = {
    1: "Êò≠Âíå„ÅÆÂÆùÁÆ±", 2: "Êáê„Åã„Åó„ÅÆÊ≠åË¨°Êõ≤ch", 3: "ÊÄù„ÅÑÂá∫„É©„É≥„Ç≠„É≥„Ç∞", 4: "Êò≠Âíå„Çπ„Çø„ÉºÂêçÈëë",
    5: "ÊºîÊ≠å„ÅÆÊÆøÂ†Ç", 6: "ÈäÄÂπï„ÅÆÊÄù„ÅÑÂá∫", 7: "Êáê„É°„É≠Â§©ÂõΩ", 8: "Êúù„Éâ„É©Â§ßÂÖ®ÈõÜ",
    9: "Êò≠Âíå„Éó„É¨„Ç§„Éê„ÉÉ„ÇØ", 10: "Êò≠Âíå„Éé„Çπ„Çø„É´„Ç∏„Ç¢", 11: "ÈªÑÈáëÊôÇ‰ª£ch", 12: "Êò≠Âíå„Éâ„É©„ÉûÂäáÂ†¥",
    13: "Êà¶ÂæåÊó•Êú¨„ÅÆË®òÊÜ∂", 14: "Êò≠Âíå„ÅÆÂ≠¶Ê†°", 15: "Âà∂Êúç„Å®Ê†°Ââách", 16: "Êò≠Âíå„ÅÆÈ£üÂçì",
    17: "Êò≠Âíå„Ç∞„É´„É°Âõ≥Èëë", 18: "Êò≠ÂíåCMÂçöË¶ß‰ºö", 19: "CM„ÇΩ„É≥„Ç∞Â§ßÂÖ®", 20: "Êò≠Âíå„ÅÆÊöÆ„Çâ„Åó",
    21: "Êò≠Âíå„ÅÆÂÆ∂Êóè", 22: "„Åä„Åó„ÇÉ„ÇåË°óÈÅì", 23: "Êò≠Âíå„Éï„Ç°„ÉÉ„Ç∑„Éß„É≥", 24: "„É¨„Éà„É≠„Éì„É•„Éº„ÉÜ„Ç£„Éº",
    25: "Êò≠Âíå„Çπ„Éù„Éº„ÉÑ‰ºùË™¨", 26: "Êò≠Âíå„Éê„É©„Ç®„ÉÜ„Ç£", 27: "ÊøÄÂãï„ÅÆÊò≠ÂíåÂè≤"
}

def get_credentials():
    creds_json = os.environ.get('GOOGLE_CREDENTIALS_JSON')
    creds_dict = json.loads(creds_json)
    return Credentials.from_service_account_info(creds_dict, scopes=SCOPES)

def get_pending_neta(sh):
    ws = sh.worksheet('„Éç„ÇøÁÆ°ÁêÜ')
    all_data = ws.get_all_values()
    for i, row in enumerate(all_data[1:], start=2):
        if len(row) >= 6 and row[5] == 'Êú™‰ΩúÊàê':
            return {
                'row_num': i,
                'neta_id': row[0],
                'channel_id': int(row[1]),
                'category': row[2],
                'title': row[3],
                'ranking_num': int(row[4]) if row[4].isdigit() else 15
            }
    return None

def generate_ranking_content(neta):
    api_key = os.environ.get('CLAUDE_API_KEY')
    
    prompt = f"""„ÅÇ„Å™„Åü„ÅØÊò≠ÂíåÊôÇ‰ª£„ÇíÊáê„Åã„Åó„ÇÄË™û„ÇäÈÉ®„Åß„Åô„ÄÇ
‰ª•‰∏ã„ÅÆÂãïÁîª„Çø„Ç§„Éà„É´„Å´Âü∫„Å•„ÅÑ„Å¶„ÄÅ„É©„É≥„Ç≠„É≥„Ç∞ÂãïÁîª„ÅÆ„Éä„É¨„Éº„Ç∑„Éß„É≥ÂéüÁ®ø„Çí‰ΩúÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

„Çø„Ç§„Éà„É´: {neta['title']}
„É©„É≥„Ç≠„É≥„Ç∞Êï∞: TOP{neta['ranking_num']}

„ÄêÈáçË¶Å„Å™Èõ∞Âõ≤Ê∞ó‚ë†ÔºöÊôÇ„ÅÆÊµÅ„Çå„ÅÆÂàá„Å™„Åï„Äë
ÂÖ®‰Ωì„ÇíÈÄö„Åó„Å¶„ÄåÊôÇ„ÅÆÊµÅ„Çå„ÅÆÂàá„Å™„Åï„Äç„ÇíÊÑü„Åò„Åï„Åõ„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
- „Äå„ÅÇ„ÅÆÈ†É„ÅÆËºù„Åç„ÅØ„ÄÅ‰ªä„ÇÇÁßÅ„Åü„Å°„ÅÆÂøÉ„ÅÆ‰∏≠„Å´Áîü„Åç„Å¶„ÅÑ„Åæ„Åô„Äç
- „Äå„Åô„Å£„Åã„ÇäÊôÇÈñì„ÅåÁµå„Å£„Å¶„Åó„Åæ„ÅÑ„Åæ„Åó„Åü„Å≠„Äç
- „ÄåÊôÇ„ÅÆÊµÅ„Çå„ÅØÂàá„Å™„ÅÑ„ÇÇ„ÅÆ„Åß„Åô„Åå„ÄÅ„Å†„Åã„Çâ„Åì„ÅùÊÄù„ÅÑÂá∫„ÅØÁæé„Åó„ÅÑ„ÅÆ„Åã„ÇÇ„Åó„Çå„Åæ„Åõ„Çì„Äç
- „Äå„ÅÇ„Çå„Åã„Çâ‰ΩïÂçÅÂπ¥...Ë°ó„ÅÆÊôØËâ≤„ÅØÂ§â„Çè„Å£„Å¶„ÇÇ„ÄÅ„ÅÇ„ÅÆÈ†É„ÅÆË®òÊÜ∂„ÅØËâ≤Ë§™„Åõ„Åæ„Åõ„Çì„Äç
- „Äå‰ªä„ÅØ„ÇÇ„ÅÜË¶ã„Çã„Åì„Å®„Åå„Åß„Åç„Å™„ÅÑÈ¢®ÊôØ„Åß„Åô„Åå...„Äç

„ÄêÈáçË¶Å„Å™Èõ∞Âõ≤Ê∞ó‚ë°ÔºöË¶ñËÅ¥ËÄÖ„ÇíÁß∞„Åà„ÄÅËá™ÂàÜ„Åî„Å®„Å´„Äë
Ë¶ã„Å¶„ÅÑ„ÇãË¶ñËÅ¥ËÄÖËá™Ë∫´„ÇíÁß∞„Åà„ÄÅ„ÄåËá™ÂàÜ„ÅÆ‰∫∫Áîü„Å†„Äç„Å®ÊÑü„Åò„Çâ„Çå„Çã„Çà„ÅÜ„Å´„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
- „Äå„Åì„Çå„Çí„ÅîË¶ß„ÅÆ„ÅÇ„Å™„Åü„ÇÇ„ÄÅ„Åç„Å£„Å®„ÅÇ„ÅÆÊôÇ‰ª£„ÇíÊá∏ÂëΩ„Å´Áîü„Åç„Å¶„Åì„Çâ„Çå„Åü„ÅÆ„Åß„Åô„Å≠„Äç
- „Äå„ÅÇ„Å™„Åü„Åå„ÅÑ„Åü„Åã„Çâ„Åì„Åù„ÄÅ„ÅÇ„ÅÆÊôÇ‰ª£„ÅØËºù„ÅÑ„Å¶„ÅÑ„Åü„ÅÆ„Åß„Åô„Äç
- „Äå‰ªäÊó•„Åæ„ÅßÊ≠©„Çì„Åß„Åì„Çâ„Çå„Åü‰∫∫Áîü„ÄÅÊú¨ÂΩì„Å´Á¥†Êô¥„Çâ„Åó„ÅÑ„ÇÇ„ÅÆ„Åß„Åô„Äç
- „Äå„ÅÇ„Å™„Åü„ÅÆË®òÊÜ∂„ÅÆ‰∏≠„Å´„ÇÇ„ÄÅ„Åç„Å£„Å®„Åì„Çì„Å™ÊÄù„ÅÑÂá∫„Åå„ÅÇ„Çã„ÅÆ„Åß„ÅØ„Å™„ÅÑ„Åß„Åó„Çá„ÅÜ„Åã„Äç
- „Äå„Åì„ÅÆÊôÇ‰ª£„ÇíÁü•„Çã„ÅÇ„Å™„Åü„Å†„Åã„Çâ„Åì„Åù„ÄÅÂàÜ„Åã„ÇãÂñú„Å≥„Åå„ÅÇ„Çä„Åæ„Åô„Çà„Å≠„Äç
- „Äå„ÅÇ„Å™„Åü„ÅåÁ©ç„ÅøÈáç„Å≠„Å¶„Åç„ÅüÊó•„ÄÖ„Åå„ÄÅ„Å©„Çå„Åª„Å©Â∞ä„ÅÑ„ÇÇ„ÅÆ„Åã„Äç
- „ÄåÂÖ±„Å´ÊôÇ‰ª£„ÇíÁîü„Åç„ÅüÁßÅ„Åü„Å°„Å†„Åã„Çâ„Åì„Åù„ÄÅÂàÜ„Åã„Å°Âêà„Åà„ÇãÊÄù„ÅÑÂá∫„Åß„Åô„Äç

Ë¶ñËÅ¥ËÄÖ„Å´„ÄåÁßÅ„ÅÆ‰∫∫Áîü„ÇíË™ç„ÇÅ„Å¶„ÇÇ„Çâ„Åà„Åü„Äç„ÄåÁßÅ„ÅÆÊôÇ‰ª£„ÅØ‰æ°ÂÄ§„Åå„ÅÇ„Å£„Åü„Äç„Å®ÊÑü„Åò„Åï„Åõ„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

Êù°‰ª∂:
- 60Ê≠≥‰ª•‰∏ä„ÅÆÂ•≥ÊÄßË¶ñËÅ¥ËÄÖÂêë„Åë
- ÂêÑÈ†Ü‰Ωç„Å´„Å§„ÅÑ„Å¶2-3Êñá„ÅßËß£Ë™¨
- „Åó„Åø„Åò„Åø„Å®„Åó„Åü„ÄÅÂàá„Å™„Åè„ÇÇÊ∏©„Åã„ÅÑË™û„ÇäÂè£
- Ë¶ñËÅ¥ËÄÖ„Å´Áõ¥Êé•Ë™û„Çä„Åã„Åë„Çã„Çà„ÅÜ„Å´Ôºà„Äå„ÅÇ„Å™„Åü„Äç„ÄåÁöÜ„Åï„Åæ„Äç„Çí‰Ωø„ÅÜÔºâ
- „Äå„ÅÇ„ÅÆÈ†É„Äç„Å®„Äå‰ªä„Äç„ÇíÂØæÊØî„Åï„Åõ„ÄÅÊôÇ‰ª£„ÅÆÁßª„ÇäÂ§â„Çè„Çä„ÇíÊÑü„Åò„Åï„Åõ„Çã
- ‰∫åÂ∫¶„Å®Êàª„Çå„Å™„ÅÑÈÅéÂéª„Å∏„ÅÆÊÑõ„Åä„Åó„Åï„ÇíË°®Áèæ
- „Ç™„Éº„Éó„Éã„É≥„Ç∞„Å®„Ç®„É≥„Éá„Ç£„É≥„Ç∞„ÅØÁâπ„Å´ÊÑüÂÇ∑ÁöÑ„Å´„ÄÅË¶ñËÅ¥ËÄÖ„Å∏„ÅÆÊÑüË¨ù„ÇíËæº„ÇÅ„Å¶
- 8ÂàÜÁ®ãÂ∫¶„ÅÆÂãïÁîª„Å´„Å™„ÇãÂàÜÈáè

‰ª•‰∏ã„ÅÆÂΩ¢Âºè„ÅßÂá∫Âäõ:
[„Ç™„Éº„Éó„Éã„É≥„Ç∞]
ÔºàË¶ñËÅ¥ËÄÖ„Å´Ë™û„Çä„Åã„Åë„ÄÅÊôÇ„ÅÆÊµÅ„Çå„ÇíÊÑü„Åò„Åï„Åõ„ÇãÂ∞éÂÖ•„ÄÇ30ÁßíÁ®ãÂ∫¶Ôºâ

[Á¨¨{neta['ranking_num']}‰Ωç]
È†ÖÁõÆÂêç: ‚óã‚óã‚óã
Ëß£Ë™¨: Ôºà2-3Êñá„ÄÇ„Äå„ÅÇ„Å™„Åü„ÇÇË¶ö„Åà„Å¶„ÅÑ„Åæ„Åô„ÅãÔºü„Äç„Å™„Å©Ë¶ñËÅ¥ËÄÖ„Å´Âïè„ÅÑ„Åã„Åë„Å™„Åå„ÇâÔºâ

[Á¨¨{neta['ranking_num']-1}‰Ωç]
...

[Á¨¨1‰Ωç]
È†ÖÁõÆÂêç: ‚óã‚óã‚óã
Ëß£Ë™¨: Ôºà2-3Êñá„ÄÇÊúÄ„ÇÇÂç∞Ë±°ÁöÑ„Å™„Ç®„Éî„ÇΩ„Éº„Éâ„ÇíÔºâ

[„Ç®„É≥„Éá„Ç£„É≥„Ç∞]
ÔºàË¶ñËÅ¥ËÄÖ„Å∏„ÅÆÊÑüË¨ù„Å®Âä¥„ÅÑ„ÄÅÊôÇ„ÅÆÊµÅ„Çå„ÇíÊåØ„ÇäËøî„Çä„ÄÅÂøÉ„Å´ÊÆã„Çã„Åæ„Å®„ÇÅ„ÄÇ„Äå„ÅÇ„Å™„Åü„ÅÆ‰∫∫Áîü„ÅØÁ¥†Êô¥„Çâ„Åó„ÅÑ„Äç„Å®„ÅÑ„ÅÜ„É°„ÉÉ„Çª„Éº„Ç∏„ÇíËæº„ÇÅ„Å¶Ôºâ"""

    url = "https://api.anthropic.com/v1/messages"
    headers = {
        "x-api-key": api_key,
        "anthropic-version": "2023-06-01",
        "content-type": "application/json"
    }
    payload = {
        "model": "claude-3-haiku-20240307",
        "max_tokens": 4000,
        "messages": [{"role": "user", "content": prompt}]
    }
    
    try:
        response = requests.post(url, headers=headers, json=payload)
        result = response.json()
        if 'content' in result:
            return result['content'][0]['text']
    except Exception as e:
        print(f"  ‚ö†Ô∏è ÂéüÁ®øÁîüÊàê„Ç®„É©„Éº: {e}")
    return None

def generate_audio_google_tts(text, output_path):
    from gtts import gTTS
    
    try:
        max_chars = 5000
        if len(text) > max_chars:
            text = text[:max_chars]
        
        tts = gTTS(text=text, lang='ja', slow=False)
        tts.save(output_path)
        return True
    except Exception as e:
        print(f"  ‚ö†Ô∏è Èü≥Â£∞ÁîüÊàê„Ç®„É©„Éº: {e}")
    return False

# Japanese to English keyword mapping for Unsplash search
KEYWORD_MAP = {
    # Categories
    'Ê≠åË¨°Êõ≤': 'japanese music vintage',
    'ÊºîÊ≠å': 'japanese traditional music',
    'Êò†Áîª': 'vintage cinema japan',
    'ÈäÄÂπï': 'classic movie theater',
    '„Éâ„É©„Éû': 'vintage television japan',
    'Êúù„Éâ„É©': 'japanese morning drama vintage',
    'CM': 'vintage advertisement japan',
    'Â∫ÉÂëä': 'retro advertising',
    '„Éï„Ç°„ÉÉ„Ç∑„Éß„É≥': 'vintage fashion 1960s 1970s',
    '„Åä„Åó„ÇÉ„Çå': 'retro style fashion',
    'ÂåñÁ≤ßÂìÅ': 'vintage cosmetics beauty',
    '„Éì„É•„Éº„ÉÜ„Ç£„Éº': 'retro beauty makeup',
    'È£üÂçì': 'japanese home cooking vintage',
    '„Ç∞„É´„É°': 'vintage japanese food',
    'Â≠¶Ê†°': 'vintage school classroom japan',
    'Âà∂Êúç': 'japanese school uniform vintage',
    '„Çπ„Éù„Éº„ÉÑ': 'vintage sports japan',
    '„Éê„É©„Ç®„ÉÜ„Ç£': 'japanese entertainment vintage',
    'ÊöÆ„Çâ„Åó': 'vintage japanese lifestyle',
    'ÂÆ∂Êóè': 'japanese family vintage',
    'Êò≠Âíå': 'japan 1960s 1970s vintage',
    '„É¨„Éà„É≠': 'retro vintage nostalgic',
    'Êáê„Åã„Åó„ÅÑ': 'nostalgic vintage memories',
    'ÊÄù„ÅÑÂá∫': 'memories nostalgia vintage',
    '„Çπ„Çø„Éº': 'vintage celebrity star',
    'ÂêçÈëë': 'vintage portrait classic',
    'Êà¶Âæå': 'postwar japan vintage',
    'ÈªÑÈáëÊôÇ‰ª£': 'golden age vintage',
    'Ê≠¥Âè≤': 'japanese history vintage',
}

# Fallback search queries for different themes
FALLBACK_QUERIES = [
    'vintage japan street',
    'retro japanese aesthetic',
    'nostalgic sunset',
    'vintage paper texture',
    'retro gradient background',
    'old photograph sepia',
    'cherry blossom vintage',
    'japanese garden peaceful',
]

def translate_to_english_keywords(japanese_text):
    """Convert Japanese title/category to English keywords for Unsplash."""
    keywords = []

    # Check for matching keywords in the text
    for jp_word, en_keywords in KEYWORD_MAP.items():
        if jp_word in japanese_text:
            keywords.append(en_keywords)

    # If no keywords found, use general nostalgic terms
    if not keywords:
        keywords = ['vintage japan nostalgic', 'retro aesthetic']

    # Combine and deduplicate
    combined = ' '.join(keywords[:3])  # Limit to avoid overly complex queries
    return combined

def get_unsplash_images(query, count=10, category=''):
    """Fetch images from Unsplash with English keyword translation."""
    api_key = os.environ.get('UNSPLASH_ACCESS_KEY')
    url = "https://api.unsplash.com/search/photos"
    headers = {"Authorization": f"Client-ID {api_key}"}

    # Translate Japanese to English keywords
    english_query = translate_to_english_keywords(query + ' ' + category)
    print(f"    üîç Ê§úÁ¥¢„Ç≠„Éº„ÉØ„Éº„Éâ: {english_query}")

    # Try multiple search strategies
    search_queries = [
        english_query,
        'vintage japan nostalgic',
        'retro aesthetic background',
    ]

    all_urls = []
    for search_query in search_queries:
        if len(all_urls) >= count:
            break

        params = {
            "query": search_query,
            "per_page": min(count - len(all_urls) + 5, 30),  # Get extra in case of duplicates
            "orientation": "landscape"
        }

        try:
            response = requests.get(url, params=params, headers=headers)
            result = response.json()
            if 'results' in result:
                for img in result['results']:
                    img_url = img['urls']['regular']
                    if img_url not in all_urls:
                        all_urls.append(img_url)
                        if len(all_urls) >= count:
                            break
        except Exception as e:
            print(f"    ‚ö†Ô∏è Ê§úÁ¥¢„Ç®„É©„Éº ({search_query}): {e}")

    return all_urls[:count]

def generate_gradient_background(output_path, width=1280, height=720, style='showa'):
    """Generate a nostalgic gradient background image."""
    from PIL import Image, ImageDraw, ImageFilter
    import random

    # Color palettes for different styles
    palettes = {
        'showa': [
            [(139, 90, 43), (205, 133, 63)],      # Sepia brown
            [(70, 50, 30), (150, 100, 50)],       # Dark brown to tan
            [(80, 60, 40), (180, 140, 90)],       # Earthy tones
            [(100, 70, 50), (200, 160, 100)],     # Warm vintage
        ],
        'sunset': [
            [(255, 94, 77), (255, 154, 139)],     # Coral sunset
            [(255, 123, 84), (255, 184, 140)],    # Orange sunset
            [(180, 80, 100), (255, 150, 120)],    # Pink sunset
        ],
        'nostalgic': [
            [(60, 60, 80), (120, 100, 140)],      # Muted purple
            [(50, 70, 90), (100, 130, 150)],      # Dusty blue
            [(80, 70, 60), (160, 140, 120)],      # Faded vintage
        ]
    }

    # Select palette
    palette_list = palettes.get(style, palettes['showa'])
    colors = random.choice(palette_list)

    # Create gradient image
    img = Image.new('RGB', (width, height))
    draw = ImageDraw.Draw(img)

    # Vertical gradient
    for y in range(height):
        ratio = y / height
        r = int(colors[0][0] + (colors[1][0] - colors[0][0]) * ratio)
        g = int(colors[0][1] + (colors[1][1] - colors[0][1]) * ratio)
        b = int(colors[0][2] + (colors[1][2] - colors[0][2]) * ratio)
        draw.line([(0, y), (width, y)], fill=(r, g, b))

    # Add subtle noise/grain for vintage effect
    noise_img = Image.new('RGB', (width, height))
    noise_draw = ImageDraw.Draw(noise_img)
    for _ in range(5000):
        x = random.randint(0, width - 1)
        y = random.randint(0, height - 1)
        gray = random.randint(0, 30)
        noise_draw.point((x, y), fill=(gray, gray, gray))

    # Blend noise with gradient
    img = Image.blend(img, noise_img, 0.05)

    # Add vignette effect
    vignette = Image.new('L', (width, height), 255)
    vignette_draw = ImageDraw.Draw(vignette)
    for i in range(min(width, height) // 2):
        alpha = int(255 * (1 - (i / (min(width, height) / 2)) ** 2))
        vignette_draw.ellipse(
            [i, i, width - i, height - i],
            outline=alpha
        )
    vignette = vignette.filter(ImageFilter.GaussianBlur(50))

    # Apply vignette
    img_array = list(img.getdata())
    vignette_array = list(vignette.getdata())
    result_data = []
    for i, (pixel, v) in enumerate(zip(img_array, vignette_array)):
        factor = v / 255
        result_data.append((
            int(pixel[0] * factor),
            int(pixel[1] * factor),
            int(pixel[2] * factor)
        ))
    img.putdata(result_data)

    img.save(output_path, 'JPEG', quality=90)
    return True

def get_images_with_fallback(title, category, count, tmpdir):
    """Get images from Unsplash with fallback to generated backgrounds."""
    images = []

    # Try to get images from Unsplash
    search_query = f"{title} {category}"
    image_urls = get_unsplash_images(search_query, count, category)

    # Download Unsplash images
    for i, url in enumerate(image_urls):
        img_path = os.path.join(tmpdir, f"img_{i}.jpg")
        if download_image(url, img_path):
            images.append(img_path)

    # If we don't have enough images, generate fallback backgrounds
    if len(images) < count:
        print(f"    üé® „Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØËÉåÊôØ„ÇíÁîüÊàê‰∏≠...")
        styles = ['showa', 'sunset', 'nostalgic']
        for i in range(len(images), count):
            img_path = os.path.join(tmpdir, f"fallback_{i}.jpg")
            style = styles[i % len(styles)]
            if generate_gradient_background(img_path, style=style):
                images.append(img_path)

    return images

def download_image(url, output_path):
    try:
        response = requests.get(url, timeout=30)
        if response.status_code == 200:
            with open(output_path, 'wb') as f:
                f.write(response.content)
            return True
    except:
        pass
    return False

def create_video_with_moviepy(audio_path, images, title, output_path):
    from moviepy import (
        AudioFileClip, ImageClip,
        concatenate_videoclips, ColorClip
    )

    audio = AudioFileClip(audio_path)
    duration = audio.duration

    img_duration = duration / len(images) if images else duration

    clips = []
    for img_path in images:
        try:
            img_clip = ImageClip(img_path, duration=img_duration)
            img_clip = img_clip.resized(height=720)
            clips.append(img_clip)
        except Exception as e:
            print(f"  ‚ö†Ô∏è ÁîªÂÉèË™≠„ÅøËæº„Åø„Ç®„É©„Éº: {e}")

    if not clips:
        clips = [ColorClip(size=(1280, 720), color=(0,0,0), duration=duration)]

    video = concatenate_videoclips(clips, method="compose")
    video = video.with_audio(audio)

    video.write_videofile(
        output_path,
        fps=24,
        codec='libx264',
        audio_codec='aac'
    )

    audio.close()
    return True

def get_youtube_credentials(channel_id):
    """Get YouTube OAuth credentials for the channel.

    Supports two token formats:
    1. JSON format: {"refresh_token": "...", "client_id": "...", "client_secret": "..."}
    2. Simple string: 1//0e... (refresh_token only, uses YOUTUBE_CLIENT_ID/SECRET env vars)
    """
    # Determine which token to use (1-9: TOKEN_1, 10-18: TOKEN_2, 19-27: TOKEN_3)
    token_num = ((channel_id - 1) // 9) + 1
    token_env_name = f'TOKEN_{token_num}'

    token_value = os.environ.get(token_env_name) or os.environ.get('TOKEN_1')
    if not token_value:
        raise ValueError(f"{token_env_name} not found in environment variables")

    # Default credentials from environment
    default_client_id = os.environ.get('YOUTUBE_CLIENT_ID', '')
    default_client_secret = os.environ.get('YOUTUBE_CLIENT_SECRET', '')

    # Check if token is JSON format or simple string
    token_value = token_value.strip()
    if token_value.startswith('{'):
        # JSON format
        token_data = json.loads(token_value)
        refresh_token = token_data.get('refresh_token')
        client_id = token_data.get('client_id') or default_client_id
        client_secret = token_data.get('client_secret') or default_client_secret
    else:
        # Simple string format (refresh_token only)
        refresh_token = token_value
        client_id = default_client_id
        client_secret = default_client_secret

    if not client_id or not client_secret:
        raise ValueError("YOUTUBE_CLIENT_ID and YOUTUBE_CLIENT_SECRET must be set")

    creds = OAuthCredentials(
        token=None,
        refresh_token=refresh_token,
        token_uri='https://oauth2.googleapis.com/token',
        client_id=client_id,
        client_secret=client_secret,
        scopes=['https://www.googleapis.com/auth/youtube.upload']
    )

    return creds

def upload_to_youtube(file_path, title, description, channel_id, privacy='private'):
    """Upload video to YouTube and return the video URL."""
    creds = get_youtube_credentials(channel_id)
    youtube = build('youtube', 'v3', credentials=creds)

    # Prepare video metadata
    body = {
        'snippet': {
            'title': title,
            'description': description,
            'tags': ['Êò≠Âíå', 'Êáê„Åã„Åó„ÅÑ', '„É©„É≥„Ç≠„É≥„Ç∞', 'ÊÄù„ÅÑÂá∫'],
            'categoryId': '22'  # People & Blogs
        },
        'status': {
            'privacyStatus': privacy,  # 'private', 'unlisted', or 'public'
            'selfDeclaredMadeForKids': False
        }
    }

    media = MediaFileUpload(
        file_path,
        mimetype='video/mp4',
        resumable=True,
        chunksize=1024*1024  # 1MB chunks
    )

    request = youtube.videos().insert(
        part='snippet,status',
        body=body,
        media_body=media
    )

    response = None
    while response is None:
        status, response = request.next_chunk()
        if status:
            print(f"    üì§ {int(status.progress() * 100)}%")

    video_id = response.get('id')
    video_url = f"https://www.youtube.com/watch?v={video_id}"

    return video_url

def update_sheet_status(sh, row_num, status, video_url=''):
    """Update status and YouTube URL in spreadsheet."""
    ws = sh.worksheet('„Éç„ÇøÁÆ°ÁêÜ')
    ws.update_cell(row_num, 6, status)
    if video_url:
        ws.update_cell(row_num, 9, video_url)

def main():
    print("üé¨ ÂãïÁîªÁîüÊàêÈñãÂßã...")

    creds = get_credentials()
    gc = gspread.authorize(creds)
    sh = gc.open_by_key(SPREADSHEET_ID)

    # Get channel info from spreadsheet
    channel_number = int(os.environ.get('CHANNEL_NUMBER', 1))
    channel_name = get_channel_name(sh, channel_number)
    if channel_name:
        print(f"üì∫ „ÉÅ„É£„É≥„Éç„É´: {channel_name} (TOKEN_{channel_number})")
    else:
        # Fallback to hardcoded name
        channel_name = CHANNELS.get(channel_number, f"„ÉÅ„É£„É≥„Éç„É´{channel_number}")
        print(f"üì∫ „ÉÅ„É£„É≥„Éç„É´: {channel_name} (TOKEN_{channel_number}) [„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ]")

    neta = get_pending_neta(sh)
    if not neta:
        print("üì≠ Êú™‰ΩúÊàê„ÅÆ„Éç„Çø„Åå„ÅÇ„Çä„Åæ„Åõ„Çì")
        return

    print(f"üìù „Éç„Çø: {neta['title']}")

    update_sheet_status(sh, neta['row_num'], '‰ΩúÊàê‰∏≠')

    with tempfile.TemporaryDirectory() as tmpdir:
        print("  üìù ÂéüÁ®øÁîüÊàê‰∏≠...")
        script = generate_ranking_content(neta)
        if not script:
            update_sheet_status(sh, neta['row_num'], '„Ç®„É©„Éº')
            return
        print(f"  ‚úÖ ÂéüÁ®øÁîüÊàêÂÆå‰∫ÜÔºà{len(script)}ÊñáÂ≠óÔºâ")

        print("  üé§ Èü≥Â£∞ÁîüÊàê‰∏≠...")
        audio_path = os.path.join(tmpdir, "audio.mp3")
        if not generate_audio_google_tts(script, audio_path):
            update_sheet_status(sh, neta['row_num'], '„Ç®„É©„Éº')
            return
        print("  ‚úÖ Èü≥Â£∞ÁîüÊàêÂÆå‰∫Ü")

        print("  üñºÔ∏è ÁîªÂÉèÂèñÂæó‰∏≠...")
        images = get_images_with_fallback(
            title=neta['title'],
            category=neta['category'],
            count=neta['ranking_num'],
            tmpdir=tmpdir
        )
        print(f"  ‚úÖ ÁîªÂÉèÂèñÂæóÂÆå‰∫ÜÔºà{len(images)}ÊûöÔºâ")

        print("  üé• ÂãïÁîªÁîüÊàê‰∏≠...")
        video_path = os.path.join(tmpdir, "output.mp4")
        if not create_video_with_moviepy(audio_path, images, neta['title'], video_path):
            update_sheet_status(sh, neta['row_num'], '„Ç®„É©„Éº')
            return
        print("  ‚úÖ ÂãïÁîªÁîüÊàêÂÆå‰∫Ü")

        print("  üì∫ YouTube„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ‰∏≠...")
        # Create description with channel name
        description = f"{script[:100]}...\n\n"
        if channel_name:
            description += f"„Äê{channel_name}„Äë\n"
        description += "#Êò≠Âíå #Êáê„Åã„Åó„ÅÑ #„É©„É≥„Ç≠„É≥„Ç∞ #ÊÄù„ÅÑÂá∫ #„É¨„Éà„É≠"

        video_url = upload_to_youtube(
            file_path=video_path,
            title=neta['title'],
            description=description,
            channel_id=neta['channel_id'],
            privacy='private'  # Test with private
        )
        print(f"  ‚úÖ „Ç¢„ÉÉ„Éó„É≠„Éº„ÉâÂÆå‰∫Ü")

        update_sheet_status(sh, neta['row_num'], 'ÂÆåÊàê', video_url)

    print(f"üéâ ÂãïÁîªÁîüÊàêÂÆå‰∫ÜÔºÅ {video_url}")

if __name__ == "__main__":
    main()
