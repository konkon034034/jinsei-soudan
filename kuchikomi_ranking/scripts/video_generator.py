#!/usr/bin/env python3
"""
å£ã‚³ãƒŸãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒãƒ£ãƒ³ãƒãƒ« - å‹•ç”»ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 
Gemini TTSã§éŸ³å£°ç”Ÿæˆã€ffmpegã§å‹•ç”»åˆæˆ
"""

import os
import sys
import json
import wave
import struct
import tempfile
import subprocess
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed

# è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent))
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from dotenv import load_dotenv
load_dotenv(Path(__file__).parent.parent.parent / ".env")

from google import genai
from google.genai import types
from PIL import Image, ImageDraw, ImageFont

# ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from character_settings import CHARACTERS, get_voice_for_speaker
except ImportError:
    CHARACTERS = {
        "ã‚«ãƒ„ãƒŸ": {"voice": "kore", "color_rgb": (255, 228, 181)},
        "ãƒ’ãƒ­ã‚·": {"voice": "puck", "color_rgb": (100, 149, 237)}
    }
    def get_voice_for_speaker(speaker):
        return CHARACTERS.get(speaker, {}).get("voice", "kore")


# ===== å®šæ•° =====
VIDEO_WIDTH = 1920
VIDEO_HEIGHT = 1080
SAMPLE_RATE = 24000
TTS_MODEL = "gemini-2.5-flash-preview-tts"


class GeminiKeyManager:
    """è¤‡æ•°ã®Gemini APIã‚­ãƒ¼ã‚’ç®¡ç†"""

    def __init__(self):
        self.keys = []
        # åŸºæœ¬ã‚­ãƒ¼
        base_key = os.environ.get("GEMINI_API_KEY")
        if base_key:
            self.keys.append(base_key)
        # ç•ªå·ä»˜ãã‚­ãƒ¼
        for i in range(1, 43):
            key = os.environ.get(f"GEMINI_API_KEY_{i}")
            if key:
                self.keys.append(key)

        if not self.keys:
            raise ValueError("GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

        print(f"âœ“ Gemini APIã‚­ãƒ¼: {len(self.keys)}å€‹")
        self.current_index = 0

    def get_key(self) -> str:
        """æ¬¡ã®ã‚­ãƒ¼ã‚’å–å¾—"""
        key = self.keys[self.current_index]
        self.current_index = (self.current_index + 1) % len(self.keys)
        return key


import time

def generate_tts_single(text: str, voice: str, api_key: str, output_path: str, max_retries: int = 3) -> bool:
    """
    å˜ä¸€ã®ã‚»ãƒªãƒ•ã‚’TTSã§éŸ³å£°ç”Ÿæˆ

    Args:
        text: ã‚»ãƒªãƒ•ãƒ†ã‚­ã‚¹ãƒˆ
        voice: éŸ³å£°åï¼ˆkore, puck ãªã© - å°æ–‡å­—ï¼‰
        api_key: Gemini APIã‚­ãƒ¼
        output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        max_retries: æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°

    Returns:
        æˆåŠŸã—ãŸã‚‰True
    """
    # ãƒœã‚¤ã‚¹åã‚’å°æ–‡å­—ã«æ­£è¦åŒ–
    voice = voice.lower()

    for attempt in range(max_retries):
        try:
            client = genai.Client(api_key=api_key)

            response = client.models.generate_content(
                model=TTS_MODEL,
                contents=text,
                config=types.GenerateContentConfig(
                    response_modalities=["AUDIO"],
                    speech_config=types.SpeechConfig(
                        voice_config=types.VoiceConfig(
                            prebuilt_voice_config=types.PrebuiltVoiceConfig(
                                voice_name=voice
                            )
                        )
                    )
                )
            )

            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            audio_data = response.candidates[0].content.parts[0].inline_data.data

            # WAVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
            with wave.open(output_path, 'wb') as wav_file:
                wav_file.setnchannels(1)
                wav_file.setsampwidth(2)  # 16-bit
                wav_file.setframerate(SAMPLE_RATE)
                wav_file.writeframes(audio_data)

            return True

        except Exception as e:
            error_str = str(e)
            if "429" in error_str or "RESOURCE_EXHAUSTED" in error_str:
                # ãƒ¬ãƒ¼ãƒˆåˆ¶é™: å¾…æ©Ÿã—ã¦ãƒªãƒˆãƒ©ã‚¤
                wait_time = 20 * (attempt + 1)  # 20ç§’, 40ç§’, 60ç§’
                print(f"    â³ ãƒ¬ãƒ¼ãƒˆåˆ¶é™ - {wait_time}ç§’å¾…æ©Ÿä¸­...")
                time.sleep(wait_time)
                continue
            else:
                print(f"âš ï¸ TTSç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
                return False

    print(f"âš ï¸ TTSç”Ÿæˆå¤±æ•—ï¼ˆãƒªãƒˆãƒ©ã‚¤ä¸Šé™ï¼‰")
    return False


def generate_all_audio(dialogue: list, temp_dir: Path, key_manager: GeminiKeyManager) -> list:
    """
    å…¨ã‚»ãƒªãƒ•ã®éŸ³å£°ã‚’é †æ¬¡ç”Ÿæˆï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼‰

    Returns:
        [(audio_path, speaker, text, duration), ...]
    """
    print("ğŸ¤ éŸ³å£°ã‚’ç”Ÿæˆä¸­...")
    print("   (ãƒ¬ãƒ¼ãƒˆåˆ¶é™: 1åˆ†ã‚ãŸã‚Š3ãƒªã‚¯ã‚¨ã‚¹ãƒˆ - å„ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¾Œã«20ç§’å¾…æ©Ÿ)")

    audio_files = []

    # é †æ¬¡å‡¦ç†ï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–: 3 requests/min = 20ç§’é–“éš”ï¼‰
    for i, line in enumerate(dialogue):
        speaker = line["speaker"]
        text = line["text"]
        voice = get_voice_for_speaker(speaker)

        output_path = str(temp_dir / f"audio_{i:03d}.wav")
        api_key = key_manager.get_key()

        print(f"  [{i+1}/{len(dialogue)}] {speaker}: {text[:20]}...")

        success = generate_tts_single(text, voice, api_key, output_path)

        if success and Path(output_path).exists():
            # éŸ³å£°ã®é•·ã•ã‚’å–å¾—
            with wave.open(output_path, 'rb') as wav:
                frames = wav.getnframes()
                rate = wav.getframerate()
                duration = frames / rate

            audio_files.append({
                "path": output_path,
                "speaker": speaker,
                "text": text,
                "duration": duration,
                "index": i
            })
            print(f"    âœ“ æˆåŠŸ ({duration:.1f}ç§’)")

            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–: æ¬¡ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¾ã§å¾…æ©Ÿ
            if i < len(dialogue) - 1:
                print(f"    â³ 20ç§’å¾…æ©Ÿ...")
                time.sleep(20)
        else:
            print(f"âš ï¸ éŸ³å£°ç”Ÿæˆå¤±æ•—: {text[:20]}")

    print(f"âœ… éŸ³å£°ç”Ÿæˆå®Œäº†: {len(audio_files)}/{len(dialogue)}ä»¶")
    return audio_files


def concat_audio_files(audio_files: list, output_path: str, gap_ms: int = 300) -> float:
    """
    è¤‡æ•°ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆ

    Returns:
        ç·æ™‚é–“ï¼ˆç§’ï¼‰
    """
    print("ğŸ”Š éŸ³å£°ã‚’çµåˆä¸­...")

    # ã‚½ãƒ¼ãƒˆ
    audio_files = sorted(audio_files, key=lambda x: x["index"])

    # ç„¡éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
    gap_samples = int(SAMPLE_RATE * gap_ms / 1000)
    silence = b'\x00\x00' * gap_samples

    # çµåˆ
    all_audio = b''
    for audio in audio_files:
        with wave.open(audio["path"], 'rb') as wav:
            all_audio += wav.readframes(wav.getnframes())
        all_audio += silence

    # ä¿å­˜
    with wave.open(output_path, 'wb') as wav:
        wav.setnchannels(1)
        wav.setsampwidth(2)
        wav.setframerate(SAMPLE_RATE)
        wav.writeframes(all_audio)

    total_duration = len(all_audio) / 2 / SAMPLE_RATE
    print(f"âœ… éŸ³å£°çµåˆå®Œäº†: {total_duration:.1f}ç§’")
    return total_duration


def create_frame(title: str, speaker: str, text: str,
                 katsumi_icon: str, hiroshi_icon: str) -> Image.Image:
    """
    å‹•ç”»ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”Ÿæˆ

    ç”»é¢æ§‹æˆ:
    - ä¸Šéƒ¨: é»„è‰²ãƒãƒ¼ã«ã‚¿ã‚¤ãƒˆãƒ«
    - å·¦: ã‚«ãƒ„ãƒŸç”»åƒ
    - å³: ãƒ’ãƒ­ã‚·ç”»åƒ
    - ä¸­å¤®: å£ã‚³ãƒŸãƒ†ã‚­ã‚¹ãƒˆ
    - ä¸‹éƒ¨: å­—å¹•ãƒãƒ¼
    """
    # èƒŒæ™¯
    img = Image.new('RGB', (VIDEO_WIDTH, VIDEO_HEIGHT), (30, 30, 40))
    draw = ImageDraw.Draw(img)

    # ãƒ•ã‚©ãƒ³ãƒˆ
    try:
        font_large = ImageFont.truetype("/usr/share/fonts/truetype/fonts-japanese-gothic.ttf", 48)
        font_medium = ImageFont.truetype("/usr/share/fonts/truetype/fonts-japanese-gothic.ttf", 36)
        font_small = ImageFont.truetype("/usr/share/fonts/truetype/fonts-japanese-gothic.ttf", 28)
    except:
        try:
            font_large = ImageFont.truetype("/System/Library/Fonts/ãƒ’ãƒ©ã‚®ãƒè§’ã‚´ã‚·ãƒƒã‚¯ W6.ttc", 48)
            font_medium = ImageFont.truetype("/System/Library/Fonts/ãƒ’ãƒ©ã‚®ãƒè§’ã‚´ã‚·ãƒƒã‚¯ W6.ttc", 36)
            font_small = ImageFont.truetype("/System/Library/Fonts/ãƒ’ãƒ©ã‚®ãƒè§’ã‚´ã‚·ãƒƒã‚¯ W6.ttc", 28)
        except:
            font_large = font_medium = font_small = ImageFont.load_default()

    # ä¸Šéƒ¨: ã‚¿ã‚¤ãƒˆãƒ«ãƒãƒ¼
    draw.rectangle([0, 0, VIDEO_WIDTH, 80], fill=(255, 200, 50))
    draw.text((VIDEO_WIDTH // 2, 40), title[:40], font=font_medium,
              fill=(30, 30, 30), anchor="mm")

    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ç”»åƒ
    icon_size = 300

    # ã‚«ãƒ„ãƒŸï¼ˆå·¦ï¼‰
    try:
        katsumi_img = Image.open(katsumi_icon).convert('RGBA')
        katsumi_img = katsumi_img.resize((icon_size, icon_size))

        # è©±ã—ã¦ã„ã‚‹æ–¹ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
        if speaker == "ã‚«ãƒ„ãƒŸ":
            # ç™ºå…‰ã‚¨ãƒ•ã‚§ã‚¯ãƒˆ
            highlight = Image.new('RGBA', (icon_size + 20, icon_size + 20), (255, 228, 181, 100))
            img.paste(highlight, (90, 200), highlight)

        img.paste(katsumi_img, (100, 210), katsumi_img)
    except:
        draw.ellipse([100, 210, 400, 510], fill=(255, 228, 181))
        draw.text((250, 360), "ã‚«ãƒ„ãƒŸ", font=font_medium, fill=(30, 30, 30), anchor="mm")

    # ãƒ’ãƒ­ã‚·ï¼ˆå³ï¼‰
    try:
        hiroshi_img = Image.open(hiroshi_icon).convert('RGBA')
        hiroshi_img = hiroshi_img.resize((icon_size, icon_size))

        if speaker == "ãƒ’ãƒ­ã‚·":
            highlight = Image.new('RGBA', (icon_size + 20, icon_size + 20), (100, 149, 237, 100))
            img.paste(highlight, (VIDEO_WIDTH - 410, 200), highlight)

        img.paste(hiroshi_img, (VIDEO_WIDTH - 400, 210), hiroshi_img)
    except:
        draw.ellipse([VIDEO_WIDTH - 400, 210, VIDEO_WIDTH - 100, 510], fill=(100, 149, 237))
        draw.text((VIDEO_WIDTH - 250, 360), "ãƒ’ãƒ­ã‚·", font=font_medium, fill=(255, 255, 255), anchor="mm")

    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å
    draw.text((250, 530), "ã‚«ãƒ„ãƒŸ", font=font_small, fill=(255, 228, 181), anchor="mm")
    draw.text((VIDEO_WIDTH - 250, 530), "ãƒ’ãƒ­ã‚·", font=font_small, fill=(100, 149, 237), anchor="mm")

    # ä¸­å¤®: ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢
    text_area_x = 500
    text_area_width = VIDEO_WIDTH - 1000
    text_area_y = 600

    # ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹èƒŒæ™¯
    draw.rounded_rectangle(
        [text_area_x - 20, text_area_y - 20, text_area_x + text_area_width + 20, text_area_y + 200],
        radius=20,
        fill=(50, 50, 60)
    )

    # ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ˜ã‚Šè¿”ã—
    words = text
    max_chars_per_line = 25
    lines = []
    current_line = ""
    for char in words:
        current_line += char
        if len(current_line) >= max_chars_per_line:
            lines.append(current_line)
            current_line = ""
    if current_line:
        lines.append(current_line)

    # ãƒ†ã‚­ã‚¹ãƒˆã‚’æç”»
    y_offset = text_area_y + 20
    for line in lines[:4]:  # æœ€å¤§4è¡Œ
        draw.text((text_area_x + text_area_width // 2, y_offset),
                  line, font=font_medium, fill=(255, 255, 255), anchor="mm")
        y_offset += 50

    # ä¸‹éƒ¨: å­—å¹•ãƒãƒ¼
    subtitle_y = VIDEO_HEIGHT - 120
    speaker_color = CHARACTERS.get(speaker, {}).get("color_rgb", (255, 255, 255))

    draw.rectangle([0, subtitle_y - 10, VIDEO_WIDTH, VIDEO_HEIGHT], fill=(0, 0, 0, 180))

    # è©±è€…å
    draw.text((100, subtitle_y + 30), f"ã€{speaker}ã€‘", font=font_medium,
              fill=speaker_color, anchor="lm")

    # å­—å¹•ãƒ†ã‚­ã‚¹ãƒˆ
    subtitle_text = text[:50] + ("..." if len(text) > 50 else "")
    draw.text((300, subtitle_y + 30), subtitle_text, font=font_medium,
              fill=(255, 255, 255), anchor="lm")

    return img


def generate_video(script: dict, output_path: str, temp_dir: Path = None) -> bool:
    """
    å°æœ¬ã‹ã‚‰å‹•ç”»ã‚’ç”Ÿæˆ

    Args:
        script: å°æœ¬ãƒ‡ãƒ¼ã‚¿
        output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        temp_dir: ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª

    Returns:
        æˆåŠŸã—ãŸã‚‰True
    """
    print("ğŸ¬ å‹•ç”»ç”Ÿæˆé–‹å§‹")

    if temp_dir is None:
        temp_dir = Path(tempfile.mkdtemp())

    title = script.get("title", "å£ã‚³ãƒŸãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    dialogue = script.get("dialogue", [])

    if not dialogue:
        print("âŒ ã‚»ãƒªãƒ•ãŒã‚ã‚Šã¾ã›ã‚“")
        return False

    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚¢ã‚¤ã‚³ãƒ³ã®ãƒ‘ã‚¹
    base_dir = Path(__file__).parent.parent
    katsumi_icon = str(base_dir / "assets" / "characters" / "katsumi_icon.png")
    hiroshi_icon = str(base_dir / "assets" / "characters" / "hiroshi_icon.png")

    # 1. éŸ³å£°ç”Ÿæˆ
    key_manager = GeminiKeyManager()
    audio_files = generate_all_audio(dialogue, temp_dir, key_manager)

    if not audio_files:
        print("âŒ éŸ³å£°ç”Ÿæˆã«å¤±æ•—")
        return False

    # 2. éŸ³å£°çµåˆ
    combined_audio = str(temp_dir / "combined_audio.wav")
    total_duration = concat_audio_files(audio_files, combined_audio)

    # 3. ãƒ•ãƒ¬ãƒ¼ãƒ ç”Ÿæˆ
    print("ğŸ–¼ï¸ ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”Ÿæˆä¸­...")
    frames_dir = temp_dir / "frames"
    frames_dir.mkdir(exist_ok=True)

    # å„ã‚»ãƒªãƒ•ã«å¯¾å¿œã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”Ÿæˆ
    frame_index = 0
    fps = 30
    gap_seconds = 0.3  # ã‚»ãƒªãƒ•é–“ã®é–“éš”

    for audio in sorted(audio_files, key=lambda x: x["index"]):
        speaker = audio["speaker"]
        text = audio["text"]
        duration = audio["duration"]

        # ã“ã®ã‚»ãƒªãƒ•ã«å¿…è¦ãªãƒ•ãƒ¬ãƒ¼ãƒ æ•°
        num_frames = int((duration + gap_seconds) * fps)

        # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”Ÿæˆ
        frame = create_frame(title, speaker, text, katsumi_icon, hiroshi_icon)

        for _ in range(num_frames):
            frame_path = frames_dir / f"frame_{frame_index:05d}.png"
            frame.save(frame_path)
            frame_index += 1

    print(f"âœ… ãƒ•ãƒ¬ãƒ¼ãƒ ç”Ÿæˆå®Œäº†: {frame_index}æš")

    # 4. å‹•ç”»ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    print("ğŸ¥ å‹•ç”»ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ä¸­...")

    ffmpeg_cmd = [
        "ffmpeg", "-y",
        "-framerate", str(fps),
        "-i", str(frames_dir / "frame_%05d.png"),
        "-i", combined_audio,
        "-c:v", "libx264",
        "-preset", "fast",
        "-crf", "23",
        "-c:a", "aac",
        "-b:a", "192k",
        "-pix_fmt", "yuv420p",
        "-shortest",
        output_path
    ]

    try:
        result = subprocess.run(ffmpeg_cmd, capture_output=True, text=True)
        if result.returncode != 0:
            print(f"âŒ ffmpegã‚¨ãƒ©ãƒ¼: {result.stderr[:500]}")
            return False
    except Exception as e:
        print(f"âŒ ffmpegå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return False

    print(f"âœ… å‹•ç”»ç”Ÿæˆå®Œäº†: {output_path}")
    return True


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆ
    test_script = {
        "title": "ãƒ†ã‚¹ãƒˆå‹•ç”»",
        "dialogue": [
            {"speaker": "ã‚«ãƒ„ãƒŸ", "text": "ã‚ã‚‰ã€ä»Šæ—¥ã¯å£ã‚³ãƒŸãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ãŠå±Šã‘ã™ã‚‹ã‚ã‚ˆ"},
            {"speaker": "ãƒ’ãƒ­ã‚·", "text": "æ¥½ã—ã¿ã§ã™ã­ã€ã‚«ãƒ„ãƒŸã•ã‚“"},
            {"speaker": "ã‚«ãƒ„ãƒŸ", "text": "ç¬¬3ä½ã¯ã€100å‡ã®ä¾¿åˆ©ã‚°ãƒƒã‚ºãªã®ã‚ˆ"},
            {"speaker": "ãƒ’ãƒ­ã‚·", "text": "100å‡ã€æœ€è¿‘ã™ã”ã„ã§ã™ã‚ˆã­"},
        ]
    }

    output = "/tmp/test_video.mp4"
    success = generate_video(test_script, output)

    if success:
        print(f"\nâœ… ãƒ†ã‚¹ãƒˆå‹•ç”»ã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {output}")
    else:
        print("\nâŒ ãƒ†ã‚¹ãƒˆå¤±æ•—")
