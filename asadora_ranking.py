#!/usr/bin/env python3
"""
æœãƒ‰ãƒ©ãƒ©ãƒ³ã‚­ãƒ³ã‚°å‹•ç”»è‡ªå‹•ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 
- ãƒ¢ãƒ¼ãƒ‰A: å®Œå…¨è‡ªå‹•ï¼ˆGemini TTSï¼‰
- ãƒ¢ãƒ¼ãƒ‰B: é«˜å“è³ªï¼ˆNotebookLMï¼‰å‰åŠå‡¦ç†

å‚è€ƒ: https://zenn.dev/xtm_blog/articles/da1eba90525f91
"""

import os
import sys
import json
import re
import time
import tempfile
import requests
import random
from datetime import datetime
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from io import BytesIO
import base64
import struct
import wave

import google.generativeai as genai
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload, MediaIoBaseUpload
# moviepy 1.0.3 å¯¾å¿œ
try:
    from moviepy.editor import (
        ImageClip, AudioFileClip, TextClip, CompositeVideoClip,
        concatenate_videoclips, concatenate_audioclips
    )
except ImportError:
    # moviepy 2.0 å¯¾å¿œ
    from moviepy import (
        ImageClip, AudioFileClip, TextClip, CompositeVideoClip,
        concatenate_videoclips, concatenate_audioclips
    )
from PIL import Image, ImageDraw, ImageFont
import numpy as np


# ===== å®šæ•° =====
SPREADSHEET_ID = "15_ixYlyRp9sOlS0tdklhz6wQmwRxWlOL9cPndFWwOFo"
SHEET_NAME = "YouTubeè‡ªå‹•æŠ•ç¨¿"
VIDEO_WIDTH = 1920
VIDEO_HEIGHT = 1080
FPS = 24

# Gemini TTSè¨­å®š
VOICE_YUMIKO = "Aoede"   # å¥³æ€§å£°
VOICE_KENJI = "Charon"   # ç”·æ€§å£°

# ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®š
CHARACTERS = {
    "ãƒ¦ãƒŸã‚³": {
        "voice": VOICE_YUMIKO,
        "color": "#FF69B4",
        "description": "50ä»£å¥³æ€§ã€æœãƒ‰ãƒ©æ­´30å¹´ã€æ„Ÿæƒ…è±Šã‹"
    },
    "ã‚±ãƒ³ã‚¸": {
        "voice": VOICE_KENJI,
        "color": "#4169E1",
        "description": "40ä»£ç”·æ€§ã€æœãƒ‰ãƒ©è©•è«–å®¶ã€è±†çŸ¥è­˜è±Šå¯Œ"
    }
}


class GeminiKeyManager:
    """è¤‡æ•°ã®Gemini APIã‚­ãƒ¼ã‚’ç®¡ç†"""

    def __init__(self):
        self.keys = []
        # GEMINI_API_KEY, GEMINI_API_KEY_1, _2, _3... ã‚’åé›†
        base_key = os.environ.get("GEMINI_API_KEY")
        if base_key:
            self.keys.append(base_key)

        for i in range(1, 10):
            key = os.environ.get(f"GEMINI_API_KEY_{i}")
            if key:
                self.keys.append(key)

        if not self.keys:
            raise ValueError("GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

        self.current_index = 0

    def get_key(self):
        """æ¬¡ã®APIã‚­ãƒ¼ã‚’å–å¾—ï¼ˆãƒ©ã‚¦ãƒ³ãƒ‰ãƒ­ãƒ“ãƒ³ï¼‰"""
        key = self.keys[self.current_index]
        self.current_index = (self.current_index + 1) % len(self.keys)
        return key

    def get_random_key(self):
        """ãƒ©ãƒ³ãƒ€ãƒ ãªAPIã‚­ãƒ¼ã‚’å–å¾—"""
        return random.choice(self.keys)


def get_google_credentials():
    """Googleèªè¨¼æƒ…å ±ã‚’å–å¾—"""
    creds_json = os.environ.get("GOOGLE_SERVICE_ACCOUNT_KEY")
    if not creds_json:
        raise ValueError("GOOGLE_SERVICE_ACCOUNT_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

    creds_info = json.loads(creds_json)
    scopes = [
        "https://www.googleapis.com/auth/spreadsheets",
        "https://www.googleapis.com/auth/drive",
    ]
    return Credentials.from_service_account_info(creds_info, scopes=scopes)


def get_sheets_service():
    """Sheets APIã‚µãƒ¼ãƒ“ã‚¹ã‚’å–å¾—"""
    creds = get_google_credentials()
    return build("sheets", "v4", credentials=creds)


def get_drive_service():
    """Drive APIã‚µãƒ¼ãƒ“ã‚¹ã‚’å–å¾—"""
    creds = get_google_credentials()
    return build("drive", "v3", credentials=creds)


# ä½¿ç”¨å¯èƒ½ãªãƒãƒ£ãƒ³ãƒãƒ«ï¼ˆ3ãƒãƒ£ãƒ³ãƒãƒ«ã®ã¿ï¼‰
AVAILABLE_CHANNELS = ["23", "24", "27"]


def get_pending_task():
    """ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰PENDINGã‚¿ã‚¹ã‚¯ã‚’å–å¾—"""
    service = get_sheets_service()

    result = service.spreadsheets().values().get(
        spreadsheetId=SPREADSHEET_ID,
        range=f"{SHEET_NAME}!A:J"
    ).execute()

    values = result.get("values", [])
    headers = values[0] if values else []

    for i, row in enumerate(values[1:], start=2):
        # Cåˆ—ï¼ˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼‰ãŒPENDINGã®ã‚‚ã®ã‚’æ¢ã™
        status = row[2] if len(row) > 2 else ""
        if status == "PENDING":
            # ãƒãƒ£ãƒ³ãƒãƒ«ç•ªå·ã‚’å–å¾—ï¼ˆæœ‰åŠ¹ãªç•ªå·ã®ã¿ä½¿ç”¨ï¼‰
            channel = row[3] if len(row) > 3 else ""
            if channel not in AVAILABLE_CHANNELS:
                # ç„¡åŠ¹ãªãƒãƒ£ãƒ³ãƒãƒ«ã®å ´åˆã¯ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
                channel = random.choice(AVAILABLE_CHANNELS)
                print(f"  ãƒãƒ£ãƒ³ãƒãƒ«è‡ªå‹•é¸æŠ: {channel}")

            task = {
                "row": i,
                "theme": row[0] if len(row) > 0 else "",
                "mode": row[1] if len(row) > 1 else "AUTO",
                "status": status,
                "channel": channel,
            }
            return task

    return None


def update_spreadsheet(row: int, updates: dict):
    """ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’æ›´æ–°"""
    service = get_sheets_service()

    # åˆ—ãƒãƒƒãƒ”ãƒ³ã‚°
    col_map = {
        "status": "C",
        "search_results": "E",
        "script": "F",
        "article_url": "G",
        "audio_url": "H",
        "youtube_url": "I",
        "processing_time": "J"
    }

    for key, value in updates.items():
        if key in col_map:
            col = col_map[key]
            service.spreadsheets().values().update(
                spreadsheetId=SPREADSHEET_ID,
                range=f"{SHEET_NAME}!{col}{row}",
                valueInputOption="RAW",
                body={"values": [[str(value)[:50000]]]}  # 50000æ–‡å­—åˆ¶é™
            ).execute()


def search_asadora_info(theme: str, key_manager: GeminiKeyManager) -> str:
    """Geminiã§ã‚¦ã‚§ãƒ–æ¤œç´¢ã—ã¦æœãƒ‰ãƒ©æƒ…å ±ã‚’åé›†"""
    api_key = key_manager.get_key()
    genai.configure(api_key=api_key)

    model = genai.GenerativeModel("gemini-2.0-flash")

    prompt = f"""ã‚ãªãŸã¯æœãƒ‰ãƒ©ï¼ˆNHKé€£ç¶šãƒ†ãƒ¬ãƒ“å°èª¬ï¼‰ã®å°‚é–€å®¶ã§ã™ã€‚
ä»¥ä¸‹ã®ãƒ†ãƒ¼ãƒã«ã¤ã„ã¦ã€æ­£ç¢ºãªæƒ…å ±ã‚’èª¿æŸ»ã—ã¦ãã ã•ã„ã€‚

ãƒ†ãƒ¼ãƒ: {theme}

ã€èª¿æŸ»é …ç›®ã€‘
1. é–¢é€£ã™ã‚‹æœãƒ‰ãƒ©ä½œå“ï¼ˆ10ä½œå“ä»¥ä¸Šï¼‰
2. å„ä½œå“ã®æ”¾é€å¹´
3. ä¸»æ¼”ä¿³å„ªãƒ»å¥³å„ª
4. ã‚ã‚‰ã™ã˜ãƒ»è¦‹ã©ã“ã‚
5. è¦–è´ç‡ã‚„è©±é¡Œã«ãªã£ãŸã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰
6. å‡ºæ¼”è€…ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰

ã€å‡ºåŠ›å½¢å¼ã€‘
èª¿æŸ»çµæœã‚’è©³ç´°ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚
å„ä½œå“ã«ã¤ã„ã¦ã€ã§ãã‚‹ã ã‘å¤šãã®æƒ…å ±ã‚’å«ã‚ã¦ãã ã•ã„ã€‚
"""

    response = model.generate_content(prompt)
    return response.text


def generate_dialogue_script(theme: str, search_results: str, key_manager: GeminiKeyManager) -> dict:
    """å¯¾è«‡å½¢å¼ã®å°æœ¬ã‚’ç”Ÿæˆ"""
    api_key = key_manager.get_key()
    genai.configure(api_key=api_key)

    model = genai.GenerativeModel("gemini-2.0-flash")

    prompt = f"""ã‚ãªãŸã¯YouTubeã®æœãƒ‰ãƒ©ç´¹ä»‹ãƒãƒ£ãƒ³ãƒãƒ«ã®å°æœ¬ä½œå®¶ã§ã™ã€‚
ä»¥ä¸‹ã®æƒ…å ±ã‚’åŸºã«ã€2äººã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã«ã‚ˆã‚‹å¯¾è«‡å½¢å¼ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°å‹•ç”»å°æœ¬ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ãƒ†ãƒ¼ãƒ: {theme}

ã€èª¿æŸ»æƒ…å ±ã€‘
{search_results}

ã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã€‘
ğŸ‘© ãƒ¦ãƒŸã‚³ï¼ˆ50ä»£å¥³æ€§ï¼‰
- æœãƒ‰ãƒ©æ­´30å¹´ã®ãƒ™ãƒ†ãƒ©ãƒ³ãƒ•ã‚¡ãƒ³
- æ„Ÿæƒ…è±Šã‹ã€å…±æ„ŸåŠ›ãŒé«˜ã„
- ã€Œã‚ã‹ã‚‹ã‚ã€œã€ã€Œæ³£ã‘ã‚‹ã®ã‚ˆã­ã€œã€ãŒå£ç™–
- ã€Œã€œã‚ã­ã€ã€Œã€œã ã‚ã€ã€Œã€œã®ã‚ˆã€ãªã©ã®å£èª¿

ğŸ‘¨ ã‚±ãƒ³ã‚¸ï¼ˆ40ä»£ç”·æ€§ï¼‰
- æœãƒ‰ãƒ©è©•è«–å®¶ã€è±†çŸ¥è­˜è±Šå¯Œ
- è½ã¡ç€ã„ãŸèªã‚Šå£
- è¦–è´ç‡ã‚„è£è©±ã‚’æŒŸã‚€
- ã€Œã€œã§ã™ã­ã€ã€Œã€œã§ã—ã‚‡ã†ã€ã€Œã€œã§ã™ã‚ˆã€ãªã©ã®å£èª¿

ã€å‡ºåŠ›å½¢å¼ã€‘å¿…ãšä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
{{
    "title": "å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆ60æ–‡å­—ä»¥å†…ã€ã€æœãƒ‰ãƒ©ã€‘ã‚’å«ã‚ã‚‹ï¼‰",
    "description": "å‹•ç”»èª¬æ˜æ–‡ï¼ˆ500æ–‡å­—ç¨‹åº¦ã€æ”¹è¡Œå«ã‚€ï¼‰",
    "tags": ["ã‚¿ã‚°1", "ã‚¿ã‚°2", ...],
    "opening": [
        {{"speaker": "ãƒ¦ãƒŸã‚³", "text": "çš†ã•ã‚“ã€ã“ã‚“ã«ã¡ã¯ï¼æœãƒ‰ãƒ©ã®ã™ã¹ã¦ã¸ã‚ˆã†ã“ãï¼"}},
        {{"speaker": "ã‚±ãƒ³ã‚¸", "text": "ã“ã‚“ã«ã¡ã¯ã€‚ä»Šæ—¥ã‚‚æœãƒ‰ãƒ©ã®é­…åŠ›ã‚’ãŠå±Šã‘ã—ã¾ã™ã‚ˆã€‚"}},
        ...ï¼ˆ4ã€œ6å¾€å¾©ã€è‡ªç„¶ãªä¼šè©±ã§ï¼‰
    ],
    "rankings": [
        {{
            "rank": 10,
            "work_title": "ä½œå“å",
            "year": "æ”¾é€å¹´",
            "cast": "ä¸»æ¼”ä¿³å„ªå",
            "dialogue": [
                {{"speaker": "ãƒ¦ãƒŸã‚³", "text": "ã•ã‚ã€ç¬¬10ä½ã®ç™ºè¡¨ã‚ˆï¼"}},
                {{"speaker": "ã‚±ãƒ³ã‚¸", "text": "ç¬¬10ä½ã¯..."}},
                ...ï¼ˆ8ã€œ10å¾€å¾©ã€ä½œå“ã®é­…åŠ›ã‚’èªã‚‹ï¼‰
            ],
            "image_keyword": "ä½œå“ã‚¤ãƒ¡ãƒ¼ã‚¸ã®è‹±èªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆä¾‹: japanese countryside springï¼‰"
        }},
        ... (10ä½ã‹ã‚‰1ä½ã¾ã§10å€‹)
    ],
    "ending": [
        {{"speaker": "ãƒ¦ãƒŸã‚³", "text": "ã„ã‹ãŒã§ã—ãŸã‹ï¼Ÿ"}},
        {{"speaker": "ã‚±ãƒ³ã‚¸", "text": "ã©ã‚Œã‚‚åä½œã°ã‹ã‚Šã§ã—ãŸã­ã€‚"}},
        ...ï¼ˆ6ã€œ8å¾€å¾©ã€ã¾ã¨ã‚ã¨æ¬¡å›äºˆå‘Šï¼‰
    ]
}}

ã€é‡è¦ã€‘
- å„ã‚»ãƒªãƒ•ã¯25ã€œ50æ–‡å­—ç¨‹åº¦
- ãƒ¦ãƒŸã‚³ã¯æ„Ÿæƒ…çš„ãªãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€ã‚±ãƒ³ã‚¸ã¯å®¢è¦³çš„ãªæƒ…å ±æä¾›
- ä½œå“åã€æ”¾é€å¹´ã€ä¸»æ¼”ã¯æ­£ç¢ºã«
- è¦–è´è€…ãŒè¦‹ãŸããªã‚‹ã‚ˆã†ãªç†±é‡ã®ã‚ã‚‹ä¼šè©±ã«
- å¿…ãšæœ‰åŠ¹ãªJSONã‚’å‡ºåŠ›
"""

    response = model.generate_content(prompt)
    text = response.text

    # JSONã‚’æŠ½å‡º
    json_match = re.search(r'\{[\s\S]*\}', text)
    if not json_match:
        raise ValueError("å°æœ¬ã®JSONæŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ")

    script = json.loads(json_match.group())

    # rankingsã‚’10ä½â†’1ä½ã«ã‚½ãƒ¼ãƒˆ
    script["rankings"] = sorted(script["rankings"], key=lambda x: x["rank"], reverse=True)

    return script


def generate_notebooklm_article(theme: str, script: dict) -> str:
    """NotebookLMç”¨ã®è¨˜äº‹ã‚’ç”Ÿæˆ"""
    article = f"""# {script['title']}

## ã¯ã˜ã‚ã«

{script['description']}

---

## ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç™ºè¡¨

"""

    for item in script["rankings"]:
        article += f"""
### ç¬¬{item['rank']}ä½: {item['work_title']}ï¼ˆ{item['year']}å¹´ï¼‰

**ä¸»æ¼”:** {item['cast']}

"""
        for line in item["dialogue"]:
            article += f"**{line['speaker']}:** {line['text']}\n\n"

        article += "---\n"

    article += """
## ã¾ã¨ã‚

"""
    for line in script["ending"]:
        article += f"**{line['speaker']}:** {line['text']}\n\n"

    return article


def upload_to_drive(content: str, filename: str, folder_id: str = None) -> str:
    """Google Driveã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
    service = get_drive_service()

    file_metadata = {"name": filename}
    if folder_id:
        file_metadata["parents"] = [folder_id]

    media = MediaIoBaseUpload(
        BytesIO(content.encode('utf-8')),
        mimetype='text/plain',
        resumable=True
    )

    file = service.files().create(
        body=file_metadata,
        media_body=media,
        fields='id, webViewLink'
    ).execute()

    # å…±æœ‰è¨­å®š
    service.permissions().create(
        fileId=file['id'],
        body={'type': 'anyone', 'role': 'reader'}
    ).execute()

    return file.get('webViewLink', '')


def generate_gemini_tts(text: str, voice: str, api_key: str, output_path: str) -> bool:
    """Gemini TTSã§éŸ³å£°ç”Ÿæˆ"""
    try:
        url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key={api_key}"

        headers = {"Content-Type": "application/json"}
        data = {
            "contents": [{"parts": [{"text": text}]}],
            "generationConfig": {
                "responseModalities": ["AUDIO"],
                "speechConfig": {
                    "voiceConfig": {
                        "prebuiltVoiceConfig": {"voiceName": voice}
                    }
                }
            }
        }

        response = requests.post(url, headers=headers, json=data, timeout=120)
        response.raise_for_status()

        result = response.json()

        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        audio_data = result["candidates"][0]["content"]["parts"][0]["inlineData"]["data"]
        audio_bytes = base64.b64decode(audio_data)

        # WAVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        with open(output_path, 'wb') as f:
            f.write(audio_bytes)

        return True

    except Exception as e:
        print(f"TTSç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return False


def generate_dialogue_audio_parallel(dialogue: list, temp_dir: Path, key_manager: GeminiKeyManager) -> tuple:
    """å¯¾è©±ã®éŸ³å£°ã‚’ä¸¦åˆ—ç”Ÿæˆ"""
    audio_files = []
    segments = []

    def generate_single(index, line):
        speaker = line["speaker"]
        text = line["text"]
        voice = CHARACTERS[speaker]["voice"]
        api_key = key_manager.get_random_key()

        output_path = str(temp_dir / f"line_{index:04d}.wav")
        success = generate_gemini_tts(text, voice, api_key, output_path)

        return index, output_path, success, speaker, text

    # ä¸¦åˆ—å‡¦ç†
    with ThreadPoolExecutor(max_workers=min(5, len(dialogue))) as executor:
        futures = [executor.submit(generate_single, i, line) for i, line in enumerate(dialogue)]
        results = [f.result() for f in as_completed(futures)]

    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é †ã«ã‚½ãƒ¼ãƒˆ
    results.sort(key=lambda x: x[0])

    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆ
    total_duration = 0
    valid_files = []

    for index, path, success, speaker, text in results:
        if success and os.path.exists(path):
            try:
                audio = AudioFileClip(path)
                duration = audio.duration
                audio.close()

                segments.append({
                    "speaker": speaker,
                    "text": text,
                    "start": total_duration,
                    "end": total_duration + duration,
                    "color": CHARACTERS[speaker]["color"]
                })

                valid_files.append(path)
                total_duration += duration
            except Exception as e:
                print(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    # éŸ³å£°ã‚’çµåˆ
    combined_path = str(temp_dir / "combined.wav")
    if valid_files:
        clips = [AudioFileClip(f) for f in valid_files]
        combined = concatenate_audioclips(clips)
        combined.write_audiofile(combined_path)
        combined.close()
        for clip in clips:
            clip.close()

    return combined_path, segments, total_duration


def transcribe_with_elevenlabs(audio_path: str) -> list:
    """ElevenLabs STTã§éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—"""
    api_key = os.environ.get("ELEVENLABS_API_KEY")
    if not api_key:
        return []

    try:
        url = "https://api.elevenlabs.io/v1/speech-to-text"
        headers = {"xi-api-key": api_key}

        with open(audio_path, 'rb') as f:
            files = {"file": f}
            data = {"model_id": "scribe_v1", "language_code": "ja"}

            response = requests.post(url, headers=headers, files=files, data=data, timeout=300)
            response.raise_for_status()

        result = response.json()
        return result.get("words", [])

    except Exception as e:
        print(f"STTã‚¨ãƒ©ãƒ¼: {e}")
        return []


def match_script_with_stt(segments: list, stt_words: list) -> list:
    """å°æœ¬ã¨STTçµæœã‚’ãƒãƒƒãƒãƒ³ã‚°ã—ã¦æ­£ç¢ºãªå­—å¹•ã‚’ç”Ÿæˆ"""
    if not stt_words:
        return segments

    # STTã®ãƒ¯ãƒ¼ãƒ‰ã‚’æ™‚é–“é †ã«ã‚½ãƒ¼ãƒˆ
    stt_words.sort(key=lambda x: x.get("start", 0))

    matched_segments = []

    for seg in segments:
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®æ™‚é–“ç¯„å›²å†…ã®STTãƒ¯ãƒ¼ãƒ‰ã‚’æ¢ã™
        seg_start = seg["start"]
        seg_end = seg["end"]

        # æ™‚é–“ç¯„å›²ã‚’å°‘ã—åºƒã’ã¦ãƒãƒƒãƒãƒ³ã‚°
        margin = 0.5
        matching_words = [
            w for w in stt_words
            if w.get("start", 0) >= seg_start - margin and w.get("end", 0) <= seg_end + margin
        ]

        # STTãƒ†ã‚­ã‚¹ãƒˆã¨å°æœ¬ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¯”è¼ƒ
        stt_text = "".join([w.get("text", "") for w in matching_words])
        original_text = seg["text"]

        # å°æœ¬ãƒ†ã‚­ã‚¹ãƒˆã‚’å„ªå…ˆï¼ˆSTTã¯æ™‚é–“èª¿æ•´ã®ã¿ã«ä½¿ç”¨ï¼‰
        matched_segments.append({
            **seg,
            "text": original_text,  # å°æœ¬ã®æ­£ç¢ºãªãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨
            "stt_text": stt_text    # å‚è€ƒç”¨
        })

    return matched_segments


def fetch_unsplash_image(keyword: str, output_path: str) -> bool:
    """Unsplash APIã‹ã‚‰ç”»åƒã‚’å–å¾—"""
    access_key = os.environ.get("UNSPLASH_ACCESS_KEY")
    if not access_key:
        return False

    try:
        url = "https://api.unsplash.com/search/photos"
        params = {
            "query": keyword,
            "orientation": "landscape",
            "per_page": 5
        }
        headers = {"Authorization": f"Client-ID {access_key}"}

        response = requests.get(url, params=params, headers=headers, timeout=10)
        response.raise_for_status()

        data = response.json()
        if data["results"]:
            # ãƒ©ãƒ³ãƒ€ãƒ ã«1æšé¸æŠ
            image_data = random.choice(data["results"])
            image_url = image_data["urls"]["regular"]

            img_response = requests.get(image_url, timeout=30)
            img_response.raise_for_status()

            with open(output_path, 'wb') as f:
                f.write(img_response.content)

            resize_image(output_path, VIDEO_WIDTH, VIDEO_HEIGHT)
            return True

    except Exception as e:
        print(f"Unsplashç”»åƒå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

    return False


def generate_gradient_background(output_path: str, rank: int = 0):
    """æ˜­å’Œé¢¨ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³èƒŒæ™¯ã‚’ç”Ÿæˆ"""
    img = Image.new('RGB', (VIDEO_WIDTH, VIDEO_HEIGHT))
    draw = ImageDraw.Draw(img)

    color_schemes = [
        ((70, 35, 10), (210, 180, 140)),     # ãƒ–ãƒ©ã‚¦ãƒ³
        ((30, 50, 50), (176, 196, 222)),      # ã‚°ãƒ¬ãƒ¼
        ((80, 20, 20), (255, 218, 185)),      # ãƒãƒ«ãƒ¼ãƒ³
        ((20, 60, 20), (144, 238, 144)),      # ã‚°ãƒªãƒ¼ãƒ³
        ((50, 20, 80), (230, 230, 250)),      # ã‚¤ãƒ³ãƒ‡ã‚£ã‚´
        ((90, 20, 20), (255, 182, 193)),      # ãƒ¬ãƒƒãƒ‰
        ((20, 20, 90), (173, 216, 230)),      # ãƒ–ãƒ«ãƒ¼
        ((50, 60, 30), (238, 232, 170)),      # ã‚ªãƒªãƒ¼ãƒ–
        ((80, 20, 80), (221, 160, 221)),      # ãƒ‘ãƒ¼ãƒ—ãƒ«
        ((20, 80, 80), (224, 255, 255)),      # ãƒ†ã‚£ãƒ¼ãƒ«
        ((120, 90, 20), (255, 250, 205)),     # ã‚´ãƒ¼ãƒ«ãƒ‰ï¼ˆ1ä½ç”¨ï¼‰
    ]

    idx = (rank - 1) % len(color_schemes) if rank > 0 else 0
    if rank == 1:
        idx = 10

    top_color, bottom_color = color_schemes[idx]

    for y in range(VIDEO_HEIGHT):
        ratio = y / VIDEO_HEIGHT
        r = int(top_color[0] * (1 - ratio) + bottom_color[0] * ratio)
        g = int(top_color[1] * (1 - ratio) + bottom_color[1] * ratio)
        b = int(top_color[2] * (1 - ratio) + bottom_color[2] * ratio)
        draw.line([(0, y), (VIDEO_WIDTH, y)], fill=(r, g, b))

    img.save(output_path)


def resize_image(image_path: str, width: int, height: int):
    """ç”»åƒã‚’ãƒªã‚µã‚¤ã‚º"""
    img = Image.open(image_path)
    img_ratio = img.width / img.height
    target_ratio = width / height

    if img_ratio > target_ratio:
        new_width = int(img.height * target_ratio)
        left = (img.width - new_width) // 2
        img = img.crop((left, 0, left + new_width, img.height))
    else:
        new_height = int(img.width / target_ratio)
        top = (img.height - new_height) // 2
        img = img.crop((0, top, img.width, top + new_height))

    img = img.resize((width, height), Image.LANCZOS)
    img.save(image_path)


def get_font_path():
    """æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãƒ‘ã‚¹ã‚’å–å¾—"""
    font_paths = [
        "/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc",
        "/usr/share/fonts/noto-cjk/NotoSansCJK-Bold.ttc",
        "/usr/share/fonts/truetype/noto/NotoSansCJK-Bold.ttc",
        "/System/Library/Fonts/ãƒ’ãƒ©ã‚®ãƒè§’ã‚´ã‚·ãƒƒã‚¯ W6.ttc",
        "C:/Windows/Fonts/msgothic.ttc",
    ]
    for fp in font_paths:
        if os.path.exists(fp):
            return fp
    return None


# ===== FFmpegãƒ™ãƒ¼ã‚¹é«˜é€Ÿå‹•ç”»ç”Ÿæˆ =====

import subprocess


def combine_audio_ffmpeg(audio_files: list, output_path: str) -> bool:
    """FFmpegã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆ"""
    if not audio_files:
        return False

    if len(audio_files) == 1:
        # 1ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯ã‚³ãƒ”ãƒ¼
        import shutil
        shutil.copy(audio_files[0], output_path)
        return True

    # concatç”¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’ä½œæˆ
    list_path = output_path + ".txt"
    with open(list_path, 'w') as f:
        for audio_file in audio_files:
            f.write(f"file '{audio_file}'\n")

    cmd = [
        'ffmpeg', '-y', '-f', 'concat', '-safe', '0',
        '-i', list_path,
        '-c', 'copy',
        output_path
    ]

    try:
        subprocess.run(cmd, check=True, capture_output=True)
        os.remove(list_path)
        return True
    except subprocess.CalledProcessError as e:
        print(f"éŸ³å£°çµåˆã‚¨ãƒ©ãƒ¼: {e.stderr.decode()}")
        return False


def get_audio_duration_ffprobe(audio_path: str) -> float:
    """FFprobeã§éŸ³å£°ã®é•·ã•ã‚’å–å¾—"""
    cmd = [
        'ffprobe', '-v', 'error',
        '-show_entries', 'format=duration',
        '-of', 'default=noprint_wrappers=1:nokey=1',
        audio_path
    ]
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        return float(result.stdout.strip())
    except:
        return 0.0


def generate_ass_subtitles(segments: list, output_path: str, video_width: int, video_height: int):
    """ASSå½¢å¼ã®å­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆï¼ˆã‚¹ã‚¿ã‚¤ãƒ«ä»˜ãï¼‰"""

    # ASSãƒ˜ãƒƒãƒ€ãƒ¼
    header = f"""[Script Info]
Title: æœãƒ‰ãƒ©ãƒ©ãƒ³ã‚­ãƒ³ã‚°
ScriptType: v4.00+
PlayResX: {video_width}
PlayResY: {video_height}
ScaledBorderAndShadow: yes

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Yumiko,Noto Sans CJK JP,44,&H00B469FF,&H000000FF,&H00000000,&H80000000,-1,0,0,0,100,100,0,0,1,3,1,2,50,50,120,1
Style: Kenji,Noto Sans CJK JP,44,&H00E16941,&H000000FF,&H00000000,&H80000000,-1,0,0,0,100,100,0,0,1,3,1,2,50,50,120,1
Style: Default,Noto Sans CJK JP,44,&H00FFFFFF,&H000000FF,&H00000000,&H80000000,-1,0,0,0,100,100,0,0,1,3,1,2,50,50,120,1
Style: Rank,Noto Sans CJK JP,80,&H0000D7FF,&H000000FF,&H00000080,&H80000000,-1,0,0,0,100,100,0,0,1,4,2,7,50,50,50,1
Style: Info,Noto Sans CJK JP,48,&H00FFFFFF,&H000000FF,&H00000000,&H80000000,-1,0,0,0,100,100,0,0,1,2,1,7,100,50,150,1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
"""

    def format_ass_time(seconds: float) -> str:
        """ç§’ã‚’ASSå½¢å¼ã«å¤‰æ›"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        centis = int((seconds % 1) * 100)
        return f"{hours}:{minutes:02d}:{secs:02d}.{centis:02d}"

    lines = [header]

    for seg in segments:
        start = format_ass_time(seg['start'])
        end = format_ass_time(seg['end'])
        speaker = seg.get('speaker', '')
        text = seg.get('text', '')

        # ã‚¹ã‚¿ã‚¤ãƒ«ã‚’é¸æŠ
        if speaker == 'ãƒ¦ãƒŸã‚³':
            style = 'Yumiko'
        elif speaker == 'ã‚±ãƒ³ã‚¸':
            style = 'Kenji'
        else:
            style = 'Default'

        # è©±è€…åã‚’ä»˜åŠ 
        display_text = f"ã€{speaker}ã€‘{text}" if speaker else text

        lines.append(f"Dialogue: 0,{start},{end},{style},,0,0,0,,{display_text}")

    with open(output_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(lines))


def create_slideshow_input(sections: list, output_path: str):
    """FFmpeg concatç”¨ã®å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
    with open(output_path, 'w') as f:
        for section in sections:
            image_path = section['image']
            duration = section['duration']
            f.write(f"file '{image_path}'\n")
            f.write(f"duration {duration}\n")
        # æœ€å¾Œã®ç”»åƒã‚’è¿½åŠ ï¼ˆFFmpegã®ä»•æ§˜ã§å¿…è¦ï¼‰
        if sections:
            f.write(f"file '{sections[-1]['image']}'\n")


def add_overlay_to_image(image_path: str, output_path: str, rank: int = None,
                         work_title: str = None, year: str = None, cast: str = None):
    """èƒŒæ™¯ç”»åƒã«ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ãƒ†ã‚­ã‚¹ãƒˆã‚’ç„¼ãè¾¼ã‚€ï¼ˆPillowã§é«˜é€Ÿå‡¦ç†ï¼‰"""
    from PIL import ImageFont

    img = Image.open(image_path).convert('RGB')
    img = img.resize((VIDEO_WIDTH, VIDEO_HEIGHT), Image.LANCZOS)
    draw = ImageDraw.Draw(img)

    # ãƒ•ã‚©ãƒ³ãƒˆãƒ‘ã‚¹ã‚’å–å¾—
    font_paths = [
        "/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc",
        "/usr/share/fonts/noto-cjk/NotoSansCJK-Bold.ttc",
        "/usr/share/fonts/truetype/noto/NotoSansCJK-Bold.ttc",
        "/System/Library/Fonts/ãƒ’ãƒ©ã‚®ãƒè§’ã‚´ã‚·ãƒƒã‚¯ W6.ttc",
    ]

    font_path = None
    for fp in font_paths:
        if os.path.exists(fp):
            font_path = fp
            break

    if rank:
        # é †ä½ãƒãƒƒã‚¸ã‚’æç”»
        try:
            badge_font = ImageFont.truetype(font_path, 80) if font_path else ImageFont.load_default()
        except:
            badge_font = ImageFont.load_default()

        badge_text = f"ç¬¬{rank}ä½"
        badge_color = (255, 215, 0) if rank <= 3 else (255, 255, 255)  # gold or white

        # å½±ã‚’æç”»
        draw.text((52, 52), badge_text, font=badge_font, fill=(0, 0, 0))
        draw.text((50, 50), badge_text, font=badge_font, fill=badge_color)

        # ä½œå“æƒ…å ±ã‚’æç”»
        if work_title:
            try:
                info_font = ImageFont.truetype(font_path, 48) if font_path else ImageFont.load_default()
            except:
                info_font = ImageFont.load_default()

            info_text = f"ã€{work_title}ã€ï¼ˆ{year}å¹´ï¼‰"
            draw.text((102, 152), info_text, font=info_font, fill=(0, 0, 0))
            draw.text((100, 150), info_text, font=info_font, fill=(255, 255, 255))

            if cast:
                cast_text = f"ä¸»æ¼”: {cast}"
                draw.text((102, 212), cast_text, font=info_font, fill=(0, 0, 0))
                draw.text((100, 210), cast_text, font=info_font, fill=(255, 255, 255))

    img.save(output_path, quality=95)


def download_bgm_from_drive(temp_dir: Path) -> str:
    """Google Driveã‹ã‚‰BGMã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    bgm_folder_id = os.environ.get("BGM_FOLDER_ID")
    if not bgm_folder_id:
        return None

    try:
        from googleapiclient.http import MediaIoBaseDownload
        service = get_drive_service()

        # ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
        results = service.files().list(
            q=f"'{bgm_folder_id}' in parents and mimeType contains 'audio/'",
            fields="files(id, name)"
        ).execute()

        files = results.get('files', [])
        if not files:
            return None

        # ãƒ©ãƒ³ãƒ€ãƒ ã«1æ›²é¸æŠ
        selected = random.choice(files)
        print(f"  BGMé¸æŠ: {selected['name']}")

        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        bgm_path = str(temp_dir / "bgm.mp3")
        request = service.files().get_media(fileId=selected['id'])

        with open(bgm_path, 'wb') as f:
            downloader = MediaIoBaseDownload(f, request)
            done = False
            while not done:
                status, done = downloader.next_chunk()

        return bgm_path

    except Exception as e:
        print(f"  BGMãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def create_video_ffmpeg(sections: list, all_segments: list, temp_dir: Path) -> tuple:
    """FFmpegã§å‹•ç”»ã‚’è¶…é«˜é€Ÿç”Ÿæˆï¼ˆSRTå­—å¹• + BGMãƒŸã‚­ã‚·ãƒ³ã‚°å¯¾å¿œï¼‰"""
    print("\n" + "=" * 50)
    print("[FFmpeg] å‹•ç”»ç”Ÿæˆé–‹å§‹ï¼ˆè¶…é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ï¼‰")
    print("=" * 50)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    start_time = time.time()

    # 1. éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆ
    print("\n[1/5] éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆä¸­...")
    audio_files = [s['audio'] for s in sections if s.get('audio') and os.path.exists(s['audio'])]
    combined_audio = str(temp_dir / "combined_audio.wav")

    if not combine_audio_ffmpeg(audio_files, combined_audio):
        raise ValueError("éŸ³å£°çµåˆã«å¤±æ•—ã—ã¾ã—ãŸ")

    total_duration = get_audio_duration_ffprobe(combined_audio)
    print(f"  ç·å†ç”Ÿæ™‚é–“: {total_duration:.1f}ç§’ ({total_duration/60:.1f}åˆ†)")

    # 2. BGMã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    print("\n[2/5] BGMã‚’å–å¾—ä¸­...")
    bgm_path = download_bgm_from_drive(temp_dir)
    if bgm_path:
        print(f"  BGM: {bgm_path}")
    else:
        print("  BGMãªã—ï¼ˆéŸ³å£°ã®ã¿ï¼‰")

    # 3. èƒŒæ™¯ç”»åƒã«ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã‚’ç„¼ãè¾¼ã¿
    print("\n[3/5] èƒŒæ™¯ç”»åƒã‚’å‡¦ç†ä¸­...")
    processed_sections = []

    for i, section in enumerate(sections):
        if not section.get('audio') or not os.path.exists(section['audio']):
            continue

        duration = get_audio_duration_ffprobe(section['audio'])
        if duration <= 0:
            continue

        # ç”»åƒã‚’å‡¦ç†ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã‚’ç„¼ãè¾¼ã¿ï¼‰
        processed_image = str(temp_dir / f"slide_{i:03d}.png")
        add_overlay_to_image(
            section['image'],
            processed_image,
            rank=section.get('rank'),
            work_title=section.get('work_title'),
            year=section.get('year'),
            cast=section.get('cast')
        )

        processed_sections.append({
            'image': processed_image,
            'duration': duration
        })
        print(f"  [{i+1}/{len(sections)}] {duration:.1f}ç§’")

    # 4. SRTå­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
    print("\n[4/5] SRTå­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆä¸­...")
    srt_path = str(temp_dir / f"asadora_ranking_{timestamp}.srt")
    generate_srt(all_segments, srt_path)
    print(f"  å­—å¹•æ•°: {len(all_segments)}ä»¶")

    # 5. ç”»åƒã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
    print("\n[5/5] FFmpegã§å‹•ç”»ã‚’åˆæˆä¸­...")
    concat_file = str(temp_dir / "images.txt")
    create_slideshow_input(processed_sections, concat_file)

    output_path = str(temp_dir / f"asadora_ranking_{timestamp}.mp4")

    # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆforce_styleï¼‰
    font_style = "FontName=Noto Sans CJK JP,FontSize=24,PrimaryColour=&H00FFFFFF,OutlineColour=&H00000000,BorderStyle=1,Outline=2,Shadow=1,MarginV=80"

    # FFmpegã‚³ãƒãƒ³ãƒ‰ã‚’æ§‹ç¯‰
    if bgm_path and os.path.exists(bgm_path):
        # BGMã‚ã‚Š: éŸ³å£°ãƒŸã‚­ã‚·ãƒ³ã‚°
        filter_complex = (
            f"[1:a]volume=1.0[voice];"
            f"[2:a]volume=0.12,aloop=loop=-1:size=2e+09[bgm_loop];"
            f"[voice][bgm_loop]amix=inputs=2:duration=first:dropout_transition=2[a];"
            f"[0:v]scale={VIDEO_WIDTH}:{VIDEO_HEIGHT},subtitles={srt_path}:force_style='{font_style}'[v]"
        )

        cmd = [
            'ffmpeg', '-y',
            '-f', 'concat', '-safe', '0', '-i', concat_file,  # ç”»åƒ
            '-i', combined_audio,  # éŸ³å£°
            '-i', bgm_path,  # BGM
            '-filter_complex', filter_complex,
            '-map', '[v]', '-map', '[a]',
            '-c:v', 'libx264', '-preset', 'ultrafast', '-crf', '23',
            '-c:a', 'aac', '-b:a', '192k',
            '-pix_fmt', 'yuv420p',
            '-movflags', '+faststart',
            output_path
        ]
    else:
        # BGMãªã—: ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆ
        video_filter = f"scale={VIDEO_WIDTH}:{VIDEO_HEIGHT},subtitles={srt_path}:force_style='{font_style}'"

        cmd = [
            'ffmpeg', '-y',
            '-f', 'concat', '-safe', '0', '-i', concat_file,
            '-i', combined_audio,
            '-vf', video_filter,
            '-c:v', 'libx264', '-preset', 'ultrafast', '-crf', '23',
            '-c:a', 'aac', '-b:a', '192k',
            '-pix_fmt', 'yuv420p',
            '-shortest',
            '-movflags', '+faststart',
            output_path
        ]

    print(f"  å‡ºåŠ›: {output_path}")

    try:
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        elapsed = time.time() - start_time
        print(f"\nâœ“ å‹•ç”»ç”Ÿæˆå®Œäº†!")
        print(f"  å‡¦ç†æ™‚é–“: {elapsed:.1f}ç§’")
        print(f"  å‹•ç”»é•·: {total_duration:.1f}ç§’")
        print(f"  é€Ÿåº¦æ¯”: {total_duration/elapsed:.1f}x ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ")

    except subprocess.CalledProcessError as e:
        print(f"\nFFmpegã‚¨ãƒ©ãƒ¼: {e.stderr[:500] if e.stderr else 'unknown'}")

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯1: å­—å¹•ãªã—ã§å†è©¦è¡Œ
        print("\n[ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯] å­—å¹•ãªã—ã§å†è©¦è¡Œ...")
        cmd_fallback = [
            'ffmpeg', '-y',
            '-f', 'concat', '-safe', '0', '-i', concat_file,
            '-i', combined_audio,
            '-vf', f"scale={VIDEO_WIDTH}:{VIDEO_HEIGHT}",
            '-c:v', 'libx264', '-preset', 'ultrafast', '-crf', '23',
            '-c:a', 'aac', '-b:a', '192k',
            '-pix_fmt', 'yuv420p', '-shortest',
            '-movflags', '+faststart',
            output_path
        ]

        try:
            subprocess.run(cmd_fallback, check=True, capture_output=True)
            print("  å­—å¹•ãªã—ã§å®Œäº†")
        except subprocess.CalledProcessError as e2:
            print(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚‚å¤±æ•—: {e2.stderr[:200] if e2.stderr else 'unknown'}")
            raise

    return output_path, srt_path


def generate_srt(segments: list, output_path: str):
    """SRTãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"""
    with open(output_path, 'w', encoding='utf-8') as f:
        for i, seg in enumerate(segments, 1):
            start = format_srt_time(seg['start'])
            end = format_srt_time(seg['end'])
            speaker = seg.get('speaker', '')
            text = f"ã€{speaker}ã€‘{seg['text']}" if speaker else seg['text']
            f.write(f"{i}\n{start} --> {end}\n{text}\n\n")


def format_srt_time(seconds: float) -> str:
    """ç§’ã‚’SRTå½¢å¼ã«å¤‰æ›"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"


def create_video(script: dict, temp_dir: Path, key_manager: GeminiKeyManager) -> tuple:
    """å‹•ç”»ã‚’ä½œæˆï¼ˆFFmpegãƒ™ãƒ¼ã‚¹é«˜é€Ÿç‰ˆï¼‰"""
    sections = []  # FFmpegç”¨ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±
    all_segments = []
    current_time = 0.0

    print("å‹•ç”»ä½œæˆé–‹å§‹ï¼ˆFFmpegé«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ï¼‰...")

    # ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°
    print("[1/12] ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°éŸ³å£°ç”Ÿæˆä¸­...")
    opening_dir = temp_dir / "opening"
    opening_dir.mkdir(exist_ok=True)

    opening_audio, opening_segments, opening_duration = generate_dialogue_audio_parallel(
        script["opening"], opening_dir, key_manager
    )

    opening_bg = str(temp_dir / "opening_bg.png")
    generate_gradient_background(opening_bg, rank=0)

    if opening_duration > 0:
        sections.append({
            'audio': opening_audio,
            'image': opening_bg,
            'rank': None,
            'work_title': None,
            'year': None,
            'cast': None
        })

        for seg in opening_segments:
            all_segments.append({**seg, "start": current_time + seg["start"], "end": current_time + seg["end"]})
        current_time += opening_duration

    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    for item in script["rankings"]:
        rank = item["rank"]
        print(f"[{12 - rank}/12] ç¬¬{rank}ä½ éŸ³å£°ç”Ÿæˆä¸­...")

        rank_dir = temp_dir / f"rank_{rank}"
        rank_dir.mkdir(exist_ok=True)

        audio_path, segments, duration = generate_dialogue_audio_parallel(
            item["dialogue"], rank_dir, key_manager
        )

        # èƒŒæ™¯ç”»åƒã‚’å–å¾—
        image_path = str(temp_dir / f"rank_{rank}.jpg")
        if not fetch_unsplash_image(item.get("image_keyword", "japan drama"), image_path):
            image_path = str(temp_dir / f"rank_{rank}.png")
            generate_gradient_background(image_path, rank=rank)

        if duration > 0:
            sections.append({
                'audio': audio_path,
                'image': image_path,
                'rank': rank,
                'work_title': item.get("work_title"),
                'year': item.get("year"),
                'cast': item.get("cast")
            })

            for seg in segments:
                all_segments.append({**seg, "start": current_time + seg["start"], "end": current_time + seg["end"]})
            current_time += duration

    # ã‚¨ãƒ³ãƒ‡ã‚£ãƒ³ã‚°
    print("[12/12] ã‚¨ãƒ³ãƒ‡ã‚£ãƒ³ã‚°éŸ³å£°ç”Ÿæˆä¸­...")
    ending_dir = temp_dir / "ending"
    ending_dir.mkdir(exist_ok=True)

    ending_audio, ending_segments, ending_duration = generate_dialogue_audio_parallel(
        script["ending"], ending_dir, key_manager
    )

    ending_bg = str(temp_dir / "ending_bg.png")
    generate_gradient_background(ending_bg, rank=11)

    if ending_duration > 0:
        sections.append({
            'audio': ending_audio,
            'image': ending_bg,
            'rank': None,
            'work_title': None,
            'year': None,
            'cast': None
        })

        for seg in ending_segments:
            all_segments.append({**seg, "start": current_time + seg["start"], "end": current_time + seg["end"]})

    # FFmpegã§å‹•ç”»ç”Ÿæˆ
    if not sections:
        raise ValueError("æœ‰åŠ¹ãªã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒã‚ã‚Šã¾ã›ã‚“")

    return create_video_ffmpeg(sections, all_segments, temp_dir)


def upload_to_youtube(video_path: str, title: str, description: str, tags: list, channel_token: str) -> str:
    """YouTubeã«å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
    client_id = os.environ.get("YOUTUBE_CLIENT_ID")
    client_secret = os.environ.get("YOUTUBE_CLIENT_SECRET")

    # TOKENç’°å¢ƒå¤‰æ•°åã‚’æ§‹ç¯‰ï¼ˆYOUTUBE_REFRESH_TOKEN_X å½¢å¼ï¼‰
    token_env_name = f"YOUTUBE_REFRESH_TOKEN_{channel_token}"
    refresh_token = os.environ.get(token_env_name)

    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
    print(f"[DEBUG] TOKENç’°å¢ƒå¤‰æ•°å: {token_env_name}")
    print(f"[DEBUG] TOKENå–å¾—çµæœ: {'ã‚ã‚Š' if refresh_token else 'ãªã—'}")
    print(f"[DEBUG] CLIENT_ID: {'ã‚ã‚Š' if client_id else 'ãªã—'}")
    print(f"[DEBUG] CLIENT_SECRET: {'ã‚ã‚Š' if client_secret else 'ãªã—'}")

    if not all([client_id, client_secret, refresh_token]):
        # åˆ©ç”¨å¯èƒ½ãªç’°å¢ƒå¤‰æ•°ã‚’è¡¨ç¤º
        available_tokens = [k for k in os.environ.keys() if k.startswith("YOUTUBE_REFRESH_TOKEN")]
        print(f"[DEBUG] åˆ©ç”¨å¯èƒ½ãªTOKENç’°å¢ƒå¤‰æ•°: {available_tokens}")
        raise ValueError(f"YouTubeèªè¨¼æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™ ({token_env_name})")

    # ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—
    token_url = "https://oauth2.googleapis.com/token"
    response = requests.post(token_url, data={
        "client_id": client_id,
        "client_secret": client_secret,
        "refresh_token": refresh_token,
        "grant_type": "refresh_token"
    })
    response.raise_for_status()
    access_token = response.json()["access_token"]

    from google.oauth2.credentials import Credentials as OAuthCredentials
    creds = OAuthCredentials(
        token=access_token,
        refresh_token=refresh_token,
        token_uri=token_url,
        client_id=client_id,
        client_secret=client_secret
    )

    youtube = build("youtube", "v3", credentials=creds)

    hashtags = " ".join([f"#{tag}" for tag in tags[:5]])

    body = {
        "snippet": {
            "title": title,
            "description": f"{description}\n\n{hashtags}",
            "tags": tags,
            "categoryId": "24"
        },
        "status": {
            "privacyStatus": "public",
            "selfDeclaredMadeForKids": False
        }
    }

    media = MediaFileUpload(video_path, mimetype="video/mp4", resumable=True)
    request = youtube.videos().insert(part="snippet,status", body=body, media_body=media)

    response = None
    while response is None:
        status, response = request.next_chunk()
        if status:
            print(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é€²æ—: {int(status.progress() * 100)}%")

    video_id = response["id"]
    return f"https://www.youtube.com/watch?v={video_id}"


def send_slack_notification(message: str, success: bool = True):
    """Slacké€šçŸ¥"""
    webhook_url = os.environ.get("SLACK_WEBHOOK_URL")
    if not webhook_url:
        return

    emoji = ":white_check_mark:" if success else ":x:"
    payload = {"text": f"{emoji} *æœãƒ‰ãƒ©ãƒ©ãƒ³ã‚­ãƒ³ã‚°*\n{message}"}

    try:
        requests.post(webhook_url, json=payload, timeout=10)
    except Exception as e:
        print(f"Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")


def process_auto_mode(task: dict, key_manager: GeminiKeyManager):
    """ãƒ¢ãƒ¼ãƒ‰A: å®Œå…¨è‡ªå‹•å‡¦ç†"""
    start_time = time.time()
    row = task["row"]
    theme = task["theme"]
    channel = task["channel"]

    try:
        update_spreadsheet(row, {"status": "PROCESSING"})

        # 1. ã‚¦ã‚§ãƒ–æ¤œç´¢
        print("[1/6] ã‚¦ã‚§ãƒ–æ¤œç´¢ä¸­...")
        search_results = search_asadora_info(theme, key_manager)
        update_spreadsheet(row, {"search_results": search_results[:10000]})

        # 2. å°æœ¬ç”Ÿæˆ
        print("[2/6] å°æœ¬ç”Ÿæˆä¸­...")
        script = generate_dialogue_script(theme, search_results, key_manager)
        update_spreadsheet(row, {"script": json.dumps(script, ensure_ascii=False)[:50000]})

        # 3-5. å‹•ç”»ä½œæˆ
        print("[3/6] å‹•ç”»ä½œæˆä¸­...")
        temp_dir = Path(tempfile.mkdtemp())
        video_path, srt_path = create_video(script, temp_dir, key_manager)

        # 6. YouTubeã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        print("[6/6] YouTubeã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...")
        youtube_url = upload_to_youtube(
            video_path,
            script["title"],
            script["description"],
            script.get("tags", ["æœãƒ‰ãƒ©", "NHK", "ãƒ©ãƒ³ã‚­ãƒ³ã‚°"]),
            channel
        )

        elapsed = int(time.time() - start_time)
        update_spreadsheet(row, {
            "status": "DONE",
            "youtube_url": youtube_url,
            "processing_time": f"{elapsed}ç§’"
        })

        send_slack_notification(
            f"*å®Œå…¨è‡ªå‹•ãƒ¢ãƒ¼ãƒ‰å®Œäº†*\n"
            f"ãƒ†ãƒ¼ãƒ: {theme}\n"
            f"ã‚¿ã‚¤ãƒˆãƒ«: {script['title']}\n"
            f"URL: {youtube_url}\n"
            f"å‡¦ç†æ™‚é–“: {elapsed}ç§’"
        )

        print(f"\nå®Œäº†: {youtube_url}")

    except Exception as e:
        update_spreadsheet(row, {"status": f"ERROR: {str(e)[:100]}"})
        send_slack_notification(f"ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ\nãƒ†ãƒ¼ãƒ: {theme}\n{str(e)}", success=False)
        raise


def process_notebook_mode(task: dict, key_manager: GeminiKeyManager):
    """ãƒ¢ãƒ¼ãƒ‰B: NotebookLMå‰åŠå‡¦ç†"""
    row = task["row"]
    theme = task["theme"]

    try:
        update_spreadsheet(row, {"status": "PROCESSING"})

        # 1. ã‚¦ã‚§ãƒ–æ¤œç´¢
        print("[1/4] ã‚¦ã‚§ãƒ–æ¤œç´¢ä¸­...")
        search_results = search_asadora_info(theme, key_manager)
        update_spreadsheet(row, {"search_results": search_results[:10000]})

        # 2. å°æœ¬ç”Ÿæˆ
        print("[2/4] å°æœ¬ç”Ÿæˆä¸­...")
        script = generate_dialogue_script(theme, search_results, key_manager)
        update_spreadsheet(row, {"script": json.dumps(script, ensure_ascii=False)[:50000]})

        # 3. NotebookLMç”¨è¨˜äº‹ç”Ÿæˆ
        print("[3/4] NotebookLMç”¨è¨˜äº‹ç”Ÿæˆä¸­...")
        article = generate_notebooklm_article(theme, script)

        # 4. Google Driveã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        print("[4/4] Google Driveã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...")
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"asadora_{timestamp}.txt"
        article_url = upload_to_drive(article, filename)

        update_spreadsheet(row, {
            "status": "WAITING_AUDIO",
            "article_url": article_url
        })

        send_slack_notification(
            f"*NotebookLMç”¨è¨˜äº‹ãŒæº–å‚™ã§ãã¾ã—ãŸ*\n"
            f"ãƒ†ãƒ¼ãƒ: {theme}\n"
            f"è¨˜äº‹URL: {article_url}\n\n"
            f"1. NotebookLMã§è¨˜äº‹ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n"
            f"2. éŸ³å£°æ¦‚è¦ã‚’ç”Ÿæˆ\n"
            f"3. éŸ³å£°ã‚’Google Driveã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n"
            f"4. ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ã€ŒAUDIO_READYã€ã«æ›´æ–°"
        )

        print(f"\nè¨˜äº‹URL: {article_url}")
        print("NotebookLMã§éŸ³å£°ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„")

    except Exception as e:
        update_spreadsheet(row, {"status": f"ERROR: {str(e)[:100]}"})
        send_slack_notification(f"ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ\nãƒ†ãƒ¼ãƒ: {theme}\n{str(e)}", success=False)
        raise


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("æœãƒ‰ãƒ©ãƒ©ãƒ³ã‚­ãƒ³ã‚°å‹•ç”»è‡ªå‹•ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 60)

    try:
        key_manager = GeminiKeyManager()
        print(f"Gemini APIã‚­ãƒ¼: {len(key_manager.keys)}å€‹")

        task = get_pending_task()
        if not task:
            print("å‡¦ç†å¯¾è±¡ã®ã‚¿ã‚¹ã‚¯ãŒã‚ã‚Šã¾ã›ã‚“")
            return

        print(f"\nã‚¿ã‚¹ã‚¯ç™ºè¦‹:")
        print(f"  ãƒ†ãƒ¼ãƒ: {task['theme']}")
        print(f"  ãƒ¢ãƒ¼ãƒ‰: {task['mode']}")
        print(f"  ãƒãƒ£ãƒ³ãƒãƒ«: YOUTUBE_REFRESH_TOKEN_{task['channel']}")

        if task["mode"] == "NOTEBOOK":
            process_notebook_mode(task, key_manager)
        else:
            process_auto_mode(task, key_manager)

        print("\n" + "=" * 60)
        print("å‡¦ç†å®Œäº†")
        print("=" * 60)

    except Exception as e:
        print(f"\nã‚¨ãƒ©ãƒ¼: {e}")
        send_slack_notification(f"ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {str(e)}", success=False)
        sys.exit(1)


if __name__ == "__main__":
    main()
