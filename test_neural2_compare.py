#!/usr/bin/env python3
"""
Google Cloud TTS Neural2 å£°æ¯”è¼ƒãƒ†ã‚¹ãƒˆï¼ˆ10ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
pitch/rate ã®é•ã„ã‚’1æœ¬ã®å‹•ç”»ã§æ¯”è¼ƒ
"""

import os
import json
import subprocess
import tempfile
from pathlib import Path
from datetime import datetime

from google.cloud import texttospeech
from google.oauth2.service_account import Credentials
import requests

# ===== ãƒ†ã‚¹ãƒˆã‚»ãƒªãƒ• =====
TEST_DIALOGUE = [
    {"speaker": "ã‚«ãƒ„ãƒŸ", "text": "ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™ã€‚ä»Šæ—¥ã®å¹´é‡‘ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ãŠå±Šã‘ã—ã¾ã™ã€‚"},
    {"speaker": "ãƒ’ãƒ­ã‚·", "text": "ä»Šæ—¥ã¯ã©ã‚“ãªãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒã‚ã‚‹ã‚“ã§ã™ã‹ï¼Ÿ"},
]

# ===== 10ãƒ‘ã‚¿ãƒ¼ãƒ³ =====
VOICE_PATTERNS = [
    {"name": "ãƒ‘ã‚¿ãƒ¼ãƒ³1", "katsumi": "ja-JP-Neural2-B", "hiroshi": "ja-JP-Neural2-C", "pitch": 0.0, "rate": 1.15},
    {"name": "ãƒ‘ã‚¿ãƒ¼ãƒ³2", "katsumi": "ja-JP-Neural2-B", "hiroshi": "ja-JP-Neural2-D", "pitch": 0.0, "rate": 1.15},
    {"name": "ãƒ‘ã‚¿ãƒ¼ãƒ³3", "katsumi": "ja-JP-Neural2-B", "hiroshi": "ja-JP-Neural2-C", "pitch": 2.0, "rate": 1.15},
    {"name": "ãƒ‘ã‚¿ãƒ¼ãƒ³4", "katsumi": "ja-JP-Neural2-B", "hiroshi": "ja-JP-Neural2-D", "pitch": 2.0, "rate": 1.15},
    {"name": "ãƒ‘ã‚¿ãƒ¼ãƒ³5", "katsumi": "ja-JP-Neural2-B", "hiroshi": "ja-JP-Neural2-C", "pitch": -2.0, "rate": 1.15},
    {"name": "ãƒ‘ã‚¿ãƒ¼ãƒ³6", "katsumi": "ja-JP-Neural2-B", "hiroshi": "ja-JP-Neural2-D", "pitch": -2.0, "rate": 1.15},
    {"name": "ãƒ‘ã‚¿ãƒ¼ãƒ³7", "katsumi": "ja-JP-Neural2-B", "hiroshi": "ja-JP-Neural2-C", "pitch": 0.0, "rate": 1.25},
    {"name": "ãƒ‘ã‚¿ãƒ¼ãƒ³8", "katsumi": "ja-JP-Neural2-B", "hiroshi": "ja-JP-Neural2-D", "pitch": 0.0, "rate": 1.25},
    {"name": "ãƒ‘ã‚¿ãƒ¼ãƒ³9", "katsumi": "ja-JP-Neural2-B", "hiroshi": "ja-JP-Neural2-C", "pitch": 0.0, "rate": 1.0},
    {"name": "ãƒ‘ã‚¿ãƒ¼ãƒ³10", "katsumi": "ja-JP-Neural2-B", "hiroshi": "ja-JP-Neural2-D", "pitch": 0.0, "rate": 1.0},
]


def get_tts_client():
    """Google Cloud TTS ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—"""
    key_json = os.environ.get("GOOGLE_SERVICE_ACCOUNT_KEY")
    if not key_json:
        raise ValueError("GOOGLE_SERVICE_ACCOUNT_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    key_data = json.loads(key_json)
    credentials = Credentials.from_service_account_info(key_data)
    return texttospeech.TextToSpeechClient(credentials=credentials)


def generate_tts(client, text: str, voice_name: str, pitch: float, rate: float, output_path: str) -> bool:
    """å˜ä¸€éŸ³å£°ã‚’ç”Ÿæˆ"""
    try:
        synthesis_input = texttospeech.SynthesisInput(text=text)
        voice = texttospeech.VoiceSelectionParams(
            language_code="ja-JP",
            name=voice_name
        )
        audio_config = texttospeech.AudioConfig(
            audio_encoding=texttospeech.AudioEncoding.LINEAR16,
            sample_rate_hertz=24000,
            speaking_rate=rate,
            pitch=pitch
        )
        response = client.synthesize_speech(
            input=synthesis_input,
            voice=voice,
            audio_config=audio_config
        )
        with open(output_path, "wb") as out:
            out.write(response.audio_content)
        return True
    except Exception as e:
        print(f"  ã‚¨ãƒ©ãƒ¼: {e}")
        return False


def generate_pattern_audio(client, pattern: dict, temp_dir: Path) -> str:
    """1ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†ã®éŸ³å£°ã‚’ç”Ÿæˆ"""
    print(f"\n  {pattern['name']}")
    print(f"    ã‚«ãƒ„ãƒŸ: {pattern['katsumi']}, ãƒ’ãƒ­ã‚·: {pattern['hiroshi']}")
    print(f"    pitch={pattern['pitch']}, rate={pattern['rate']}")

    audio_files = []

    for i, line in enumerate(TEST_DIALOGUE):
        speaker = line["speaker"]
        text = line["text"]
        voice = pattern["katsumi"] if speaker == "ã‚«ãƒ„ãƒŸ" else pattern["hiroshi"]

        output_path = str(temp_dir / f"line_{i:02d}.wav")
        if generate_tts(client, text, voice, pattern["pitch"], pattern["rate"], output_path):
            audio_files.append(output_path)
            print(f"    âœ“ {speaker}: {text[:15]}...")
        else:
            print(f"    âœ— {speaker}: å¤±æ•—")

    # éŸ³å£°ã‚’çµåˆ
    combined_path = str(temp_dir / "pattern_combined.wav")
    list_file = temp_dir / "concat.txt"
    with open(list_file, 'w') as f:
        for af in audio_files:
            f.write(f"file '{af}'\n")

    subprocess.run([
        'ffmpeg', '-y', '-f', 'concat', '-safe', '0', '-i', str(list_file),
        '-acodec', 'pcm_s16le', '-ar', '24000', '-ac', '1', combined_path
    ], capture_output=True)

    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
    for af in audio_files:
        if os.path.exists(af):
            os.remove(af)

    return combined_path


def create_pattern_title_video(pattern: dict, duration: float, temp_dir: Path) -> str:
    """ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¿ã‚¤ãƒˆãƒ«å‹•ç”»ã‚’ç”Ÿæˆï¼ˆç„¡éŸ³éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯ä»˜ãï¼‰"""
    title_path = str(temp_dir / f"title_{pattern['name']}.mp4")

    # ã‚¿ã‚¤ãƒˆãƒ«ãƒ†ã‚­ã‚¹ãƒˆ
    title_text = f"{pattern['name']}"
    subtitle = f"ã‚«ãƒ„ãƒŸ={pattern['katsumi'].split('-')[-1]}, ãƒ’ãƒ­ã‚·={pattern['hiroshi'].split('-')[-1]}"
    detail = f"pitch={pattern['pitch']:+.1f}, rate={pattern['rate']}"

    # ãƒ•ã‚©ãƒ³ãƒˆãƒ‘ã‚¹ï¼ˆGitHub Actions Ubuntuç’°å¢ƒç”¨ï¼‰
    font_path = "/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc"
    if not os.path.exists(font_path):
        font_path = "/usr/share/fonts/truetype/noto/NotoSansCJK-Bold.ttc"
    if not os.path.exists(font_path):
        font_path = "/System/Library/Fonts/ãƒ’ãƒ©ã‚®ãƒè§’ã‚´ã‚·ãƒƒã‚¯ W6.ttc"  # macOS

    # å‹•ç”»ç”Ÿæˆï¼ˆç„¡éŸ³éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯ä»˜ãï¼‰
    subprocess.run([
        'ffmpeg', '-y',
        '-f', 'lavfi', '-i', f'color=c=0x1a1a2e:s=1920x1080:d={duration}',
        '-f', 'lavfi', '-i', f'anullsrc=r=48000:cl=stereo:d={duration}',
        '-vf', f"drawtext=text='{title_text}':fontfile='{font_path}':fontsize=120:fontcolor=white:x=(w-text_w)/2:y=(h-text_h)/2-100,"
               f"drawtext=text='{subtitle}':fontfile='{font_path}':fontsize=48:fontcolor=0xcccccc:x=(w-text_w)/2:y=(h-text_h)/2+50,"
               f"drawtext=text='{detail}':fontfile='{font_path}':fontsize=40:fontcolor=0x888888:x=(w-text_w)/2:y=(h-text_h)/2+120",
        '-c:v', 'libx264', '-preset', 'ultrafast', '-crf', '23',
        '-c:a', 'aac', '-b:a', '192k',
        '-t', str(duration),
        '-pix_fmt', 'yuv420p',
        title_path
    ], capture_output=True)

    return title_path


def upload_to_youtube(video_path: str, title: str, description: str) -> str:
    """YouTubeã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
    from googleapiclient.discovery import build
    from googleapiclient.http import MediaFileUpload

    client_id = os.environ.get("YOUTUBE_CLIENT_ID")
    client_secret = os.environ.get("YOUTUBE_CLIENT_SECRET")
    refresh_token = os.environ.get("YOUTUBE_REFRESH_TOKEN_23")

    if not all([client_id, client_secret, refresh_token]):
        raise ValueError("YouTubeèªè¨¼æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™")

    response = requests.post("https://oauth2.googleapis.com/token", data={
        "client_id": client_id,
        "client_secret": client_secret,
        "refresh_token": refresh_token,
        "grant_type": "refresh_token"
    })
    access_token = response.json()["access_token"]

    from google.oauth2.credentials import Credentials as OAuthCredentials
    creds = OAuthCredentials(token=access_token)
    youtube = build("youtube", "v3", credentials=creds)

    body = {
        "snippet": {
            "title": title,
            "description": description,
            "tags": ["TTS", "ãƒ†ã‚¹ãƒˆ", "Google Cloud", "Neural2"],
            "categoryId": "22"
        },
        "status": {
            "privacyStatus": "unlisted",
            "selfDeclaredMadeForKids": False
        }
    }

    media = MediaFileUpload(video_path, mimetype="video/mp4", resumable=True)
    request = youtube.videos().insert(part="snippet,status", body=body, media_body=media)

    response = None
    while response is None:
        status, response = request.next_chunk()
        if status:
            print(f"  ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é€²æ—: {int(status.progress() * 100)}%")

    video_id = response["id"]
    return f"https://www.youtube.com/watch?v={video_id}"


def main():
    print("=" * 50)
    print("Google Cloud TTS Neural2 å£°æ¯”è¼ƒãƒ†ã‚¹ãƒˆï¼ˆ10ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰")
    print(f"å®Ÿè¡Œæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 50)

    client = get_tts_client()

    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)
        video_segments = []

        # å„ãƒ‘ã‚¿ãƒ¼ãƒ³ã®éŸ³å£°ãƒ»å‹•ç”»ã‚’ç”Ÿæˆ
        for i, pattern in enumerate(VOICE_PATTERNS):
            print(f"\n[{i+1}/10] {pattern['name']} ç”Ÿæˆä¸­...")

            # éŸ³å£°ç”Ÿæˆ
            pattern_audio = generate_pattern_audio(client, pattern, temp_path)

            # éŸ³å£°ã®é•·ã•ã‚’å–å¾—
            result = subprocess.run([
                'ffprobe', '-v', 'error', '-show_entries', 'format=duration',
                '-of', 'default=noprint_wrappers=1:nokey=1', pattern_audio
            ], capture_output=True, text=True)
            audio_duration = float(result.stdout.strip()) if result.stdout.strip() else 5.0

            # ã‚¿ã‚¤ãƒˆãƒ«å‹•ç”»ç”Ÿæˆï¼ˆ2ç§’ï¼‰
            title_video = create_pattern_title_video(pattern, 2.0, temp_path)
            video_segments.append(title_video)

            # éŸ³å£°ä»˜ãå‹•ç”»ç”Ÿæˆ
            audio_video = str(temp_path / f"audio_{i}.mp4")
            subprocess.run([
                'ffmpeg', '-y',
                '-f', 'lavfi', '-i', f'color=c=0x2C2C2C:s=1920x1080:d={audio_duration}',
                '-i', pattern_audio,
                '-c:v', 'libx264', '-preset', 'ultrafast', '-crf', '23',
                '-c:a', 'aac', '-b:a', '192k', '-ar', '48000', '-ac', '2',
                '-shortest', '-pix_fmt', 'yuv420p',
                audio_video
            ], capture_output=True)
            video_segments.append(audio_video)

            # 1ç§’ã®ç„¡éŸ³å‹•ç”»ï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³é–“ï¼‰
            silence_video = str(temp_path / f"silence_{i}.mp4")
            subprocess.run([
                'ffmpeg', '-y',
                '-f', 'lavfi', '-i', 'color=c=0x1a1a2e:s=1920x1080:d=1',
                '-f', 'lavfi', '-i', 'anullsrc=r=48000:cl=stereo',
                '-c:v', 'libx264', '-preset', 'ultrafast', '-crf', '23',
                '-c:a', 'aac', '-b:a', '192k',
                '-t', '1', '-pix_fmt', 'yuv420p',
                silence_video
            ], capture_output=True)
            video_segments.append(silence_video)

            print(f"  âœ“ å®Œäº† (éŸ³å£°: {audio_duration:.1f}ç§’)")

        # å…¨å‹•ç”»ã‚’çµåˆ
        print("\n[çµåˆä¸­...]")
        concat_list = temp_path / "concat_videos.txt"
        with open(concat_list, 'w') as f:
            for seg in video_segments:
                f.write(f"file '{seg}'\n")

        final_video = str(temp_path / "neural2_compare.mp4")
        subprocess.run([
            'ffmpeg', '-y', '-f', 'concat', '-safe', '0', '-i', str(concat_list),
            '-c:v', 'libx264', '-preset', 'fast', '-crf', '23',
            '-c:a', 'aac', '-b:a', '192k',
            '-pix_fmt', 'yuv420p',
            final_video
        ], capture_output=True, check=True)

        # å‹•ç”»ã®é•·ã•ã‚’å–å¾—
        result = subprocess.run([
            'ffprobe', '-v', 'error', '-show_entries', 'format=duration',
            '-of', 'default=noprint_wrappers=1:nokey=1', final_video
        ], capture_output=True, text=True)
        total_duration = float(result.stdout.strip()) if result.stdout.strip() else 0
        print(f"âœ“ å‹•ç”»ç”Ÿæˆå®Œäº† (åˆè¨ˆ: {total_duration:.1f}ç§’)")

        # YouTubeæŠ•ç¨¿
        print("\n[YouTubeæŠ•ç¨¿ä¸­...]")
        title = f"ã€Neural2æ¯”è¼ƒã€‘Google Cloud TTS 10ãƒ‘ã‚¿ãƒ¼ãƒ³å£°æ¯”è¼ƒ {datetime.now().strftime('%Y/%m/%d')}"
        description = """Google Cloud TTS Neural2 ã®å£°æ¯”è¼ƒãƒ†ã‚¹ãƒˆï¼ˆ10ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰

ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ä¸€è¦§ã€‘
1. Neural2-B/C, pitch=0, rate=1.15
2. Neural2-B/D, pitch=0, rate=1.15
3. Neural2-B/C, pitch=+2, rate=1.15
4. Neural2-B/D, pitch=+2, rate=1.15
5. Neural2-B/C, pitch=-2, rate=1.15
6. Neural2-B/D, pitch=-2, rate=1.15
7. Neural2-B/C, pitch=0, rate=1.25
8. Neural2-B/D, pitch=0, rate=1.25
9. Neural2-B/C, pitch=0, rate=1.0
10. Neural2-B/D, pitch=0, rate=1.0

ã€ã‚»ãƒªãƒ•ã€‘
ã‚«ãƒ„ãƒŸã€ŒãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™ã€‚ä»Šæ—¥ã®å¹´é‡‘ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ãŠå±Šã‘ã—ã¾ã™ã€‚ã€
ãƒ’ãƒ­ã‚·ã€Œä»Šæ—¥ã¯ã©ã‚“ãªãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒã‚ã‚‹ã‚“ã§ã™ã‹ï¼Ÿã€
"""

        try:
            video_url = upload_to_youtube(final_video, title, description)
            print(f"\n{'=' * 50}")
            print("YouTubeæŠ•ç¨¿å®Œäº†!")
            print(f"å‹•ç”»URL: {video_url}")
            print("=" * 50)

            # Discordé€šçŸ¥
            discord_webhook = os.environ.get("DISCORD_WEBHOOK_URL")
            if discord_webhook:
                requests.post(discord_webhook, json={
                    "content": f"âœ… **Neural2 å£°æ¯”è¼ƒãƒ†ã‚¹ãƒˆå®Œäº†**\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nğŸ“º {video_url}\nâ±ï¸ {total_duration:.1f}ç§’\nğŸ¤ 10ãƒ‘ã‚¿ãƒ¼ãƒ³æ¯”è¼ƒ\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
                })

        except Exception as e:
            print(f"YouTubeæŠ•ç¨¿ã‚¨ãƒ©ãƒ¼: {e}")
            import shutil
            output_file = f"neural2_compare_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4"
            shutil.copy(final_video, output_file)
            print(f"ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜: {output_file}")


if __name__ == "__main__":
    main()
